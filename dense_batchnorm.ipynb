{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQd6yi6FbJBU",
    "outputId": "19446a5f-52a1-4f02-bce5-db14b83967d3",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install keras-tuner --upgrade\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "po0TUbgq2dq3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import keras_tuner as kt\n",
    "from keras.layers import Layer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQec6G7l2dq5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fk4gx7Vk2dq6",
    "outputId": "a306b332-a5f1-406d-c35d-2abb8403e899",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST\n",
      "x_train shape: (48000, 28, 28, 1)\n",
      "48000 train samples\n",
      "12000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "dataset = \"MNIST\"\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "if dataset == \"CIFAR10\":\n",
    "    input_shape = (32, 32, 3)\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Split the data\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=0.20, shuffle=True\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_valid.shape[0], \"validation samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTINFUYB2dq6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building the MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1e0kWG6ooWE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Building a custom layer for our random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import logging\n",
    "\n",
    "# Constraint to fix/freeze all layer weights but some (two params per layer unit)\n",
    "class FixWeights(tf.keras.constraints.Constraint):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.init_weights = tf.keras.initializers.HeNormal(seed=None)(\n",
    "            shape=self.shape\n",
    "        ).numpy()\n",
    "        self.trainable_weights_0 = []\n",
    "        self.trainable_weights_1 = []\n",
    "        rand_ints = random.sample(\n",
    "            range(0, self.shape[0] * self.shape[1]), 2 * self.shape[1]\n",
    "        )\n",
    "        # Map random ints to coordinates\n",
    "        for i in range(self.shape[0]):\n",
    "            for j in range(self.shape[1]):\n",
    "                if i * self.shape[1] + j in rand_ints:\n",
    "                    self.trainable_weights_0.append(i)\n",
    "                    self.trainable_weights_1.append(j)\n",
    "\n",
    "    def __call__(self, w):\n",
    "        new_w = np.copy(self.init_weights)\n",
    "        for i in range(len(self.trainable_weights_0)):\n",
    "            new_w[self.trainable_weights_0[i]][self.trainable_weights_1[i]] = w[\n",
    "                self.trainable_weights_0[i]\n",
    "            ][self.trainable_weights_1[i]].numpy()\n",
    "\n",
    "        return tf.convert_to_tensor(new_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FEtOacukJ6I_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomRandomLayer(Layer):\n",
    "    def __init__(self, trainable=True):\n",
    "        self.trainable = trainable\n",
    "        super(CustomRandomLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Adding two weights with shape as number of channels to make two params per channel\n",
    "        self.w1 = self.add_weight(\n",
    "            name=\"w1\",\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=\"he_normal\",\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "        self.w2 = self.add_weight(\n",
    "            name=\"w1\",\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=\"he_normal\",\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return (x * self.w1) * self.w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MaR4ygGDJqHy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fc_model_builder(\n",
    "    units_dense_layer=10,\n",
    "    dense_layers=1,\n",
    "    dense=True,\n",
    "    bn=False,\n",
    "    random=False,\n",
    "    dense_out=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper for constructing models with different trainable layers and units in dense layers.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Adding variable amount of layers\n",
    "    for i in range(0, dense_layers):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units_dense_layer,\n",
    "                activation=None,\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                use_bias=random,\n",
    "                trainable=dense,\n",
    "                kernel_constraint=FixWeights(\n",
    "                    shape=(model.layers[-1].output_shape[1], units_dense_layer)\n",
    "                )\n",
    "                if random\n",
    "                else None,\n",
    "            )\n",
    "        )\n",
    "        if bn:\n",
    "            model.add(\n",
    "                layers.BatchNormalization(\n",
    "                    beta_initializer=\"zeros\",\n",
    "                    gamma_initializer=RandomNormal(mean=0.0, stddev=1.0),\n",
    "                    trainable=True,\n",
    "                )\n",
    "            )\n",
    "        if random:\n",
    "            # model.add(CustomRandomLayer(trainable=True))\n",
    "\n",
    "            model.add(\n",
    "                layers.BatchNormalization(\n",
    "                    beta_initializer=\"zeros\",\n",
    "                    gamma_initializer=\"ones\",\n",
    "                    trainable=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        model.add(layers.Activation(\"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            num_classes,\n",
    "            activation=\"softmax\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            trainable=dense_out,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "685IamGL2dq7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fc_model_builder_dim_wrapper(\n",
    "    layer_width=784, min_hdl=2, max_hdl=4, num_hdl_interval=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function for creating the models of interest with widht and depth as variables\n",
    "    \"\"\"\n",
    "    fc_models = {}\n",
    "\n",
    "    # Build nested dict with variable number of layered models\n",
    "    for i in range(min_hdl, max_hdl + 1, num_hdl_interval):\n",
    "        fc_models[i] = {}\n",
    "\n",
    "        model_fc_all_layers = fc_model_builder(\n",
    "            units_dense_layer=layer_width,\n",
    "            dense_layers=i,\n",
    "            dense=True,\n",
    "            bn=True,\n",
    "            random=False,\n",
    "            dense_out=True,\n",
    "        )\n",
    "        vanilla_fc_model = fc_model_builder(\n",
    "            units_dense_layer=layer_width,\n",
    "            dense_layers=i,\n",
    "            dense=True,\n",
    "            bn=False,\n",
    "            random=False,\n",
    "            dense_out=True,\n",
    "        )\n",
    "        model_fc_bn = fc_model_builder(\n",
    "            units_dense_layer=layer_width,\n",
    "            dense_layers=i,\n",
    "            dense=False,\n",
    "            bn=True,\n",
    "            random=False,\n",
    "            dense_out=False,\n",
    "        )\n",
    "        model_fc_bn_out = fc_model_builder(\n",
    "            units_dense_layer=layer_width,\n",
    "            dense_layers=i,\n",
    "            dense=False,\n",
    "            bn=True,\n",
    "            random=False,\n",
    "            dense_out=True,\n",
    "        )\n",
    "        model_fc_random = fc_model_builder(\n",
    "            units_dense_layer=layer_width,\n",
    "            dense_layers=i,\n",
    "            dense=True,\n",
    "            bn=False,\n",
    "            random=True,\n",
    "            dense_out=False,\n",
    "        )\n",
    "        model_fc_out = fc_model_builder(\n",
    "            units_dense_layer=layer_width,\n",
    "            dense_layers=i,\n",
    "            dense=False,\n",
    "            bn=False,\n",
    "            random=False,\n",
    "            dense_out=True,\n",
    "        )\n",
    "        model_fc_none = fc_model_builder(\n",
    "            units_dense_layer=layer_width,\n",
    "            dense_layers=i,\n",
    "            dense=False,\n",
    "            bn=False,\n",
    "            random=False,\n",
    "            dense_out=False,\n",
    "        )\n",
    "\n",
    "        # Save models in dict\n",
    "        fc_models[i] = {\n",
    "            \"model_fc_all_layers\": model_fc_all_layers,\n",
    "            #\"vanilla_fc_model\": vanilla_fc_model,\n",
    "            \"model_fc_bn\": model_fc_bn,\n",
    "            #\"model_fc_bn_out\": model_fc_bn_out,\n",
    "            \"model_fc_random\": model_fc_random,\n",
    "            #\"model_fc_out\": model_fc_out,\n",
    "            #\"model_fc_none\": model_fc_none,\n",
    "        }\n",
    "\n",
    "    return fc_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qK-CmnrdDG-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a custom callback to change the learning rate at 70 to 100 epochs.\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch in [70, 100]:\n",
    "        return lr * 0.1\n",
    "    return lr\n",
    "\n",
    "\"\"\"\n",
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [28125, 42185], [1e-0, 1e-1, 1e-2]\n",
    ")\n",
    "\n",
    "wd = lambda: 1e-4 * schedule(step)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "sjUvgMqrJOpv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating callbacks\n",
    "log_dir = os.path.join(\"logs/\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "    )\n",
    "]\n",
    "callbacks.append(CSVLogger(log_dir + \"/\" + \"latest.csv\"))\n",
    "callbacks.append(\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    "    )\n",
    ")\n",
    "callbacks.append(keras.callbacks.LearningRateScheduler(scheduler, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6Wh1Zimzl3W",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building models of different depth and trainable layers\n",
    "fc_models = fc_model_builder_dim_wrapper(\n",
    "    layer_width=10, min_hdl=2, max_hdl=14, num_hdl_interval=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "er1X8gFY9olm",
    "outputId": "c8211dfb-76d5-46dd-eab6-46604f48751b",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.8874 - accuracy: 0.7380 - val_loss: 0.4343 - val_accuracy: 0.8742 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3734 - accuracy: 0.8956 - val_loss: 0.3256 - val_accuracy: 0.9056 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3031 - accuracy: 0.9135 - val_loss: 0.2876 - val_accuracy: 0.9176 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2738 - accuracy: 0.9215 - val_loss: 0.2669 - val_accuracy: 0.9228 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2565 - accuracy: 0.9255 - val_loss: 0.2621 - val_accuracy: 0.9270 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2436 - accuracy: 0.9293 - val_loss: 0.2605 - val_accuracy: 0.9258 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2375 - accuracy: 0.9305 - val_loss: 0.2521 - val_accuracy: 0.9253 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2318 - accuracy: 0.9323 - val_loss: 0.2521 - val_accuracy: 0.9290 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2236 - accuracy: 0.9352 - val_loss: 0.2410 - val_accuracy: 0.9300 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2196 - accuracy: 0.9359 - val_loss: 0.2580 - val_accuracy: 0.9225 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.2152 - accuracy: 0.9369 - val_loss: 0.2329 - val_accuracy: 0.9326 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2135 - accuracy: 0.9368 - val_loss: 0.2388 - val_accuracy: 0.9308 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2128 - accuracy: 0.9372 - val_loss: 0.2402 - val_accuracy: 0.9306 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2083 - accuracy: 0.9390 - val_loss: 0.2262 - val_accuracy: 0.9366 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.2014 - accuracy: 0.9402 - val_loss: 0.2289 - val_accuracy: 0.9335 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1989 - accuracy: 0.9411 - val_loss: 0.2248 - val_accuracy: 0.9354 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.1989 - accuracy: 0.9410 - val_loss: 0.2262 - val_accuracy: 0.9377 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1952 - accuracy: 0.9417 - val_loss: 0.2307 - val_accuracy: 0.9321 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1958 - accuracy: 0.9412 - val_loss: 0.2226 - val_accuracy: 0.9366 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1940 - accuracy: 0.9408 - val_loss: 0.2336 - val_accuracy: 0.9312 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.1892 - accuracy: 0.9445 - val_loss: 0.2205 - val_accuracy: 0.9374 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1880 - accuracy: 0.9451 - val_loss: 0.2237 - val_accuracy: 0.9365 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1889 - accuracy: 0.9432 - val_loss: 0.2209 - val_accuracy: 0.9365 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1876 - accuracy: 0.9440 - val_loss: 0.2179 - val_accuracy: 0.9393 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1843 - accuracy: 0.9455 - val_loss: 0.2239 - val_accuracy: 0.9348 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1833 - accuracy: 0.9450 - val_loss: 0.2187 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1811 - accuracy: 0.9458 - val_loss: 0.2238 - val_accuracy: 0.9345 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.9804 - accuracy: 0.6789 - val_loss: 0.4359 - val_accuracy: 0.8725 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3775 - accuracy: 0.8904 - val_loss: 0.3505 - val_accuracy: 0.8943 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3184 - accuracy: 0.9082 - val_loss: 0.3081 - val_accuracy: 0.9071 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2898 - accuracy: 0.9157 - val_loss: 0.2858 - val_accuracy: 0.9152 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2685 - accuracy: 0.9222 - val_loss: 0.2800 - val_accuracy: 0.9144 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2550 - accuracy: 0.9254 - val_loss: 0.2593 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2407 - accuracy: 0.9293 - val_loss: 0.2588 - val_accuracy: 0.9243 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2331 - accuracy: 0.9322 - val_loss: 0.2449 - val_accuracy: 0.9281 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2277 - accuracy: 0.9335 - val_loss: 0.2345 - val_accuracy: 0.9301 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2204 - accuracy: 0.9354 - val_loss: 0.2409 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2167 - accuracy: 0.9373 - val_loss: 0.2283 - val_accuracy: 0.9309 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2126 - accuracy: 0.9379 - val_loss: 0.2383 - val_accuracy: 0.9284 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2070 - accuracy: 0.9398 - val_loss: 0.2216 - val_accuracy: 0.9352 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2032 - accuracy: 0.9410 - val_loss: 0.2253 - val_accuracy: 0.9342 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1999 - accuracy: 0.9416 - val_loss: 0.2253 - val_accuracy: 0.9337 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1998 - accuracy: 0.9415 - val_loss: 0.2266 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.3263 - accuracy: 0.1073 - val_loss: 2.2681 - val_accuracy: 0.1269 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2480 - accuracy: 0.1686 - val_loss: 2.2321 - val_accuracy: 0.1895 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2278 - accuracy: 0.1906 - val_loss: 2.2230 - val_accuracy: 0.1901 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2228 - accuracy: 0.1916 - val_loss: 2.2192 - val_accuracy: 0.1893 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2201 - accuracy: 0.1889 - val_loss: 2.2182 - val_accuracy: 0.1873 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2190 - accuracy: 0.1869 - val_loss: 2.2168 - val_accuracy: 0.1844 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2184 - accuracy: 0.1838 - val_loss: 2.2163 - val_accuracy: 0.1825 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2183 - accuracy: 0.1822 - val_loss: 2.2161 - val_accuracy: 0.1846 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2175 - accuracy: 0.1818 - val_loss: 2.2158 - val_accuracy: 0.1806 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2173 - accuracy: 0.1794 - val_loss: 2.2156 - val_accuracy: 0.1817 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2172 - accuracy: 0.1800 - val_loss: 2.2160 - val_accuracy: 0.1774 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2172 - accuracy: 0.1781 - val_loss: 2.2152 - val_accuracy: 0.1787 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2170 - accuracy: 0.1781 - val_loss: 2.2151 - val_accuracy: 0.1785 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2168 - accuracy: 0.1787 - val_loss: 2.2153 - val_accuracy: 0.1793 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2167 - accuracy: 0.1770 - val_loss: 2.2149 - val_accuracy: 0.1759 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2159 - accuracy: 0.1752 - val_loss: 2.2151 - val_accuracy: 0.1784 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2151 - accuracy: 0.1794 - val_loss: 2.2144 - val_accuracy: 0.1793 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2149 - accuracy: 0.1804 - val_loss: 2.2134 - val_accuracy: 0.1805 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2149 - accuracy: 0.1795 - val_loss: 2.2135 - val_accuracy: 0.1798 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.2150 - accuracy: 0.1796 - val_loss: 2.2137 - val_accuracy: 0.1802 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.2149 - accuracy: 0.1804 - val_loss: 2.2137 - val_accuracy: 0.1798 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.1649 - accuracy: 0.2115 - val_loss: 2.0393 - val_accuracy: 0.2724 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.9342 - accuracy: 0.3206 - val_loss: 1.8423 - val_accuracy: 0.3728 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.7605 - accuracy: 0.4001 - val_loss: 1.7056 - val_accuracy: 0.4223 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.6751 - accuracy: 0.4280 - val_loss: 1.6534 - val_accuracy: 0.4382 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.6344 - accuracy: 0.4384 - val_loss: 1.6073 - val_accuracy: 0.4487 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.6080 - accuracy: 0.4480 - val_loss: 1.5852 - val_accuracy: 0.4577 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5888 - accuracy: 0.4542 - val_loss: 1.5694 - val_accuracy: 0.4629 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5778 - accuracy: 0.4559 - val_loss: 1.5604 - val_accuracy: 0.4675 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5671 - accuracy: 0.4627 - val_loss: 1.5502 - val_accuracy: 0.4691 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.5580 - accuracy: 0.4646 - val_loss: 1.5440 - val_accuracy: 0.4716 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5523 - accuracy: 0.4675 - val_loss: 1.5342 - val_accuracy: 0.4788 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.5460 - accuracy: 0.4706 - val_loss: 1.5291 - val_accuracy: 0.4794 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5427 - accuracy: 0.4701 - val_loss: 1.5285 - val_accuracy: 0.4760 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5386 - accuracy: 0.4717 - val_loss: 1.5245 - val_accuracy: 0.4787 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.5365 - accuracy: 0.4736 - val_loss: 1.5205 - val_accuracy: 0.4840 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.5351 - accuracy: 0.4734 - val_loss: 1.5196 - val_accuracy: 0.4798 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.5312 - accuracy: 0.4749 - val_loss: 1.5240 - val_accuracy: 0.4834 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5309 - accuracy: 0.4768 - val_loss: 1.5136 - val_accuracy: 0.4840 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5295 - accuracy: 0.4772 - val_loss: 1.5115 - val_accuracy: 0.4864 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.5300 - accuracy: 0.4779 - val_loss: 1.5092 - val_accuracy: 0.4885 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.5252 - accuracy: 0.4802 - val_loss: 1.5112 - val_accuracy: 0.4857 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.5257 - accuracy: 0.4788 - val_loss: 1.5095 - val_accuracy: 0.4875 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.5266 - accuracy: 0.4788 - val_loss: 1.5161 - val_accuracy: 0.4880 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.2580 - accuracy: 0.1885 - val_loss: 2.2164 - val_accuracy: 0.2283 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1990 - accuracy: 0.2471 - val_loss: 2.1861 - val_accuracy: 0.2550 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1799 - accuracy: 0.2581 - val_loss: 2.1763 - val_accuracy: 0.2543 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1706 - accuracy: 0.2513 - val_loss: 2.1673 - val_accuracy: 0.2387 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1518 - accuracy: 0.2181 - val_loss: 2.1483 - val_accuracy: 0.1987 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1423 - accuracy: 0.2009 - val_loss: 2.1438 - val_accuracy: 0.1983 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1321 - accuracy: 0.2257 - val_loss: 2.1304 - val_accuracy: 0.2434 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1230 - accuracy: 0.2519 - val_loss: 2.1254 - val_accuracy: 0.2486 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1195 - accuracy: 0.2595 - val_loss: 2.1232 - val_accuracy: 0.2557 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1178 - accuracy: 0.2618 - val_loss: 2.1224 - val_accuracy: 0.2567 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1166 - accuracy: 0.2613 - val_loss: 2.1205 - val_accuracy: 0.2567 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1156 - accuracy: 0.2624 - val_loss: 2.1206 - val_accuracy: 0.2555 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1149 - accuracy: 0.2635 - val_loss: 2.1193 - val_accuracy: 0.2603 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1143 - accuracy: 0.2636 - val_loss: 2.1194 - val_accuracy: 0.2583 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1136 - accuracy: 0.2643 - val_loss: 2.1184 - val_accuracy: 0.2576 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1132 - accuracy: 0.2656 - val_loss: 2.1182 - val_accuracy: 0.2573 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1126 - accuracy: 0.2645 - val_loss: 2.1175 - val_accuracy: 0.2585 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1122 - accuracy: 0.2659 - val_loss: 2.1174 - val_accuracy: 0.2583 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1118 - accuracy: 0.2659 - val_loss: 2.1170 - val_accuracy: 0.2594 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1112 - accuracy: 0.2648 - val_loss: 2.1167 - val_accuracy: 0.2583 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1109 - accuracy: 0.2671 - val_loss: 2.1161 - val_accuracy: 0.2603 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1104 - accuracy: 0.2663 - val_loss: 2.1158 - val_accuracy: 0.2574 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 2.1101 - accuracy: 0.2675 - val_loss: 2.1157 - val_accuracy: 0.2582 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 2.1097 - accuracy: 0.2678 - val_loss: 2.1154 - val_accuracy: 0.2571 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1095 - accuracy: 0.2677 - val_loss: 2.1150 - val_accuracy: 0.2547 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1093 - accuracy: 0.2664 - val_loss: 2.1150 - val_accuracy: 0.2586 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1088 - accuracy: 0.2669 - val_loss: 2.1146 - val_accuracy: 0.2570 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1088 - accuracy: 0.2673 - val_loss: 2.1143 - val_accuracy: 0.2553 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1084 - accuracy: 0.2673 - val_loss: 2.1140 - val_accuracy: 0.2546 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1082 - accuracy: 0.2665 - val_loss: 2.1144 - val_accuracy: 0.2580 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1080 - accuracy: 0.2676 - val_loss: 2.1139 - val_accuracy: 0.2582 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 2.1077 - accuracy: 0.2673 - val_loss: 2.1137 - val_accuracy: 0.2580 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 2.1076 - accuracy: 0.2660 - val_loss: 2.1146 - val_accuracy: 0.2548 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1073 - accuracy: 0.2665 - val_loss: 2.1134 - val_accuracy: 0.2594 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1073 - accuracy: 0.2667 - val_loss: 2.1129 - val_accuracy: 0.2552 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1070 - accuracy: 0.2668 - val_loss: 2.1126 - val_accuracy: 0.2567 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1068 - accuracy: 0.2659 - val_loss: 2.1129 - val_accuracy: 0.2575 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1067 - accuracy: 0.2664 - val_loss: 2.1131 - val_accuracy: 0.2541 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 2.1065 - accuracy: 0.2659 - val_loss: 2.1127 - val_accuracy: 0.2503 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.2192 - accuracy: 0.1949 - val_loss: 2.1289 - val_accuracy: 0.2505 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0886 - accuracy: 0.2723 - val_loss: 2.0449 - val_accuracy: 0.3010 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.0260 - accuracy: 0.3007 - val_loss: 1.9978 - val_accuracy: 0.3126 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.9887 - accuracy: 0.3093 - val_loss: 1.9676 - val_accuracy: 0.3250 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.9639 - accuracy: 0.3151 - val_loss: 1.9473 - val_accuracy: 0.3287 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.9467 - accuracy: 0.3193 - val_loss: 1.9322 - val_accuracy: 0.3291 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.9337 - accuracy: 0.3211 - val_loss: 1.9211 - val_accuracy: 0.3353 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.9236 - accuracy: 0.3241 - val_loss: 1.9121 - val_accuracy: 0.3342 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.9156 - accuracy: 0.3256 - val_loss: 1.9044 - val_accuracy: 0.3311 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.9089 - accuracy: 0.3273 - val_loss: 1.8987 - val_accuracy: 0.3341 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.9034 - accuracy: 0.3280 - val_loss: 1.8932 - val_accuracy: 0.3355 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8985 - accuracy: 0.3286 - val_loss: 1.8891 - val_accuracy: 0.3382 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8942 - accuracy: 0.3304 - val_loss: 1.8848 - val_accuracy: 0.3377 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8906 - accuracy: 0.3313 - val_loss: 1.8814 - val_accuracy: 0.3396 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8874 - accuracy: 0.3321 - val_loss: 1.8781 - val_accuracy: 0.3392 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8843 - accuracy: 0.3321 - val_loss: 1.8754 - val_accuracy: 0.3408 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8817 - accuracy: 0.3345 - val_loss: 1.8727 - val_accuracy: 0.3397 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8792 - accuracy: 0.3344 - val_loss: 1.8702 - val_accuracy: 0.3425 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8769 - accuracy: 0.3352 - val_loss: 1.8684 - val_accuracy: 0.3418 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8750 - accuracy: 0.3350 - val_loss: 1.8660 - val_accuracy: 0.3427 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8731 - accuracy: 0.3370 - val_loss: 1.8642 - val_accuracy: 0.3444 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8713 - accuracy: 0.3371 - val_loss: 1.8624 - val_accuracy: 0.3443 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8696 - accuracy: 0.3372 - val_loss: 1.8608 - val_accuracy: 0.3464 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8681 - accuracy: 0.3390 - val_loss: 1.8592 - val_accuracy: 0.3437 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8666 - accuracy: 0.3380 - val_loss: 1.8577 - val_accuracy: 0.3463 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8651 - accuracy: 0.3397 - val_loss: 1.8565 - val_accuracy: 0.3447 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8639 - accuracy: 0.3403 - val_loss: 1.8554 - val_accuracy: 0.3471 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8627 - accuracy: 0.3403 - val_loss: 1.8541 - val_accuracy: 0.3477 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8616 - accuracy: 0.3410 - val_loss: 1.8529 - val_accuracy: 0.3470 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8604 - accuracy: 0.3417 - val_loss: 1.8516 - val_accuracy: 0.3483 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8593 - accuracy: 0.3427 - val_loss: 1.8506 - val_accuracy: 0.3474 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8584 - accuracy: 0.3422 - val_loss: 1.8500 - val_accuracy: 0.3476 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8575 - accuracy: 0.3421 - val_loss: 1.8488 - val_accuracy: 0.3489 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8566 - accuracy: 0.3433 - val_loss: 1.8479 - val_accuracy: 0.3474 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8557 - accuracy: 0.3435 - val_loss: 1.8471 - val_accuracy: 0.3503 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8549 - accuracy: 0.3437 - val_loss: 1.8460 - val_accuracy: 0.3507 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8540 - accuracy: 0.3457 - val_loss: 1.8454 - val_accuracy: 0.3495 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8533 - accuracy: 0.3437 - val_loss: 1.8447 - val_accuracy: 0.3492 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8525 - accuracy: 0.3444 - val_loss: 1.8436 - val_accuracy: 0.3521 - lr: 0.0100\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8517 - accuracy: 0.3460 - val_loss: 1.8432 - val_accuracy: 0.3521 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8512 - accuracy: 0.3449 - val_loss: 1.8424 - val_accuracy: 0.3548 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8505 - accuracy: 0.3459 - val_loss: 1.8416 - val_accuracy: 0.3548 - lr: 0.0100\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8499 - accuracy: 0.3461 - val_loss: 1.8409 - val_accuracy: 0.3551 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8493 - accuracy: 0.3468 - val_loss: 1.8405 - val_accuracy: 0.3550 - lr: 0.0100\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8487 - accuracy: 0.3471 - val_loss: 1.8398 - val_accuracy: 0.3547 - lr: 0.0100\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8482 - accuracy: 0.3464 - val_loss: 1.8393 - val_accuracy: 0.3547 - lr: 0.0100\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8476 - accuracy: 0.3479 - val_loss: 1.8386 - val_accuracy: 0.3529 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8470 - accuracy: 0.3480 - val_loss: 1.8381 - val_accuracy: 0.3519 - lr: 0.0100\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8465 - accuracy: 0.3478 - val_loss: 1.8375 - val_accuracy: 0.3559 - lr: 0.0100\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8460 - accuracy: 0.3490 - val_loss: 1.8375 - val_accuracy: 0.3555 - lr: 0.0100\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8455 - accuracy: 0.3481 - val_loss: 1.8368 - val_accuracy: 0.3544 - lr: 0.0100\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 52/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8450 - accuracy: 0.3481 - val_loss: 1.8361 - val_accuracy: 0.3561 - lr: 0.0100\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 53/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8446 - accuracy: 0.3484 - val_loss: 1.8356 - val_accuracy: 0.3580 - lr: 0.0100\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 54/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8442 - accuracy: 0.3490 - val_loss: 1.8353 - val_accuracy: 0.3569 - lr: 0.0100\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 55/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8437 - accuracy: 0.3489 - val_loss: 1.8348 - val_accuracy: 0.3560 - lr: 0.0100\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 56/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8433 - accuracy: 0.3493 - val_loss: 1.8343 - val_accuracy: 0.3558 - lr: 0.0100\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 57/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8429 - accuracy: 0.3489 - val_loss: 1.8340 - val_accuracy: 0.3570 - lr: 0.0100\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 58/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8425 - accuracy: 0.3495 - val_loss: 1.8334 - val_accuracy: 0.3592 - lr: 0.0100\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 59/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8421 - accuracy: 0.3508 - val_loss: 1.8333 - val_accuracy: 0.3563 - lr: 0.0100\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 60/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8417 - accuracy: 0.3500 - val_loss: 1.8326 - val_accuracy: 0.3568 - lr: 0.0100\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 61/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8414 - accuracy: 0.3507 - val_loss: 1.8323 - val_accuracy: 0.3573 - lr: 0.0100\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 62/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8410 - accuracy: 0.3503 - val_loss: 1.8321 - val_accuracy: 0.3557 - lr: 0.0100\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 63/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8407 - accuracy: 0.3504 - val_loss: 1.8317 - val_accuracy: 0.3571 - lr: 0.0100\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 64/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8403 - accuracy: 0.3506 - val_loss: 1.8315 - val_accuracy: 0.3602 - lr: 0.0100\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 65/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8400 - accuracy: 0.3515 - val_loss: 1.8309 - val_accuracy: 0.3567 - lr: 0.0100\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 66/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8397 - accuracy: 0.3509 - val_loss: 1.8309 - val_accuracy: 0.3563 - lr: 0.0100\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 67/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8394 - accuracy: 0.3513 - val_loss: 1.8301 - val_accuracy: 0.3571 - lr: 0.0100\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 68/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8391 - accuracy: 0.3515 - val_loss: 1.8300 - val_accuracy: 0.3568 - lr: 0.0100\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 69/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8387 - accuracy: 0.3509 - val_loss: 1.8297 - val_accuracy: 0.3614 - lr: 0.0100\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 70/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8385 - accuracy: 0.3514 - val_loss: 1.8293 - val_accuracy: 0.3584 - lr: 0.0100\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 71/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8382 - accuracy: 0.3517 - val_loss: 1.8289 - val_accuracy: 0.3602 - lr: 0.0100\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 72/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8380 - accuracy: 0.3523 - val_loss: 1.8288 - val_accuracy: 0.3572 - lr: 0.0100\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 73/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8376 - accuracy: 0.3516 - val_loss: 1.8284 - val_accuracy: 0.3584 - lr: 0.0100\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 74/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8373 - accuracy: 0.3520 - val_loss: 1.8283 - val_accuracy: 0.3600 - lr: 0.0100\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 75/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8371 - accuracy: 0.3519 - val_loss: 1.8280 - val_accuracy: 0.3584 - lr: 0.0100\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 76/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8369 - accuracy: 0.3530 - val_loss: 1.8275 - val_accuracy: 0.3594 - lr: 0.0100\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 77/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8367 - accuracy: 0.3529 - val_loss: 1.8274 - val_accuracy: 0.3593 - lr: 0.0100\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 78/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8364 - accuracy: 0.3519 - val_loss: 1.8270 - val_accuracy: 0.3586 - lr: 0.0100\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 79/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.8362 - accuracy: 0.3528 - val_loss: 1.8270 - val_accuracy: 0.3602 - lr: 0.0100\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 80/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.8359 - accuracy: 0.3523 - val_loss: 1.8268 - val_accuracy: 0.3564 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.4822 - accuracy: 0.0838 - val_loss: 2.4826 - val_accuracy: 0.0845 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4822 - accuracy: 0.0838 - val_loss: 2.4826 - val_accuracy: 0.0845 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4822 - accuracy: 0.0838 - val_loss: 2.4826 - val_accuracy: 0.0845 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4822 - accuracy: 0.0838 - val_loss: 2.4826 - val_accuracy: 0.0845 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.3701 - accuracy: 0.5280 - val_loss: 0.8921 - val_accuracy: 0.7317 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.5747 - accuracy: 0.8449 - val_loss: 0.4551 - val_accuracy: 0.8703 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3781 - accuracy: 0.8986 - val_loss: 0.3424 - val_accuracy: 0.9061 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3279 - accuracy: 0.9091 - val_loss: 0.3256 - val_accuracy: 0.9051 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3060 - accuracy: 0.9139 - val_loss: 0.3051 - val_accuracy: 0.9143 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2898 - accuracy: 0.9178 - val_loss: 0.2913 - val_accuracy: 0.9170 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2807 - accuracy: 0.9213 - val_loss: 0.2742 - val_accuracy: 0.9241 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2713 - accuracy: 0.9221 - val_loss: 0.2728 - val_accuracy: 0.9224 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2651 - accuracy: 0.9244 - val_loss: 0.2754 - val_accuracy: 0.9213 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2540 - accuracy: 0.9267 - val_loss: 0.2690 - val_accuracy: 0.9262 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2509 - accuracy: 0.9277 - val_loss: 0.2531 - val_accuracy: 0.9292 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2453 - accuracy: 0.9290 - val_loss: 0.2527 - val_accuracy: 0.9294 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.2386 - accuracy: 0.9299 - val_loss: 0.2470 - val_accuracy: 0.9302 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2355 - accuracy: 0.9314 - val_loss: 0.2547 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2271 - accuracy: 0.9345 - val_loss: 0.2530 - val_accuracy: 0.9273 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2281 - accuracy: 0.9334 - val_loss: 0.2431 - val_accuracy: 0.9307 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 0.2234 - accuracy: 0.9345 - val_loss: 0.2506 - val_accuracy: 0.9283 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 0.2188 - accuracy: 0.9354 - val_loss: 0.2404 - val_accuracy: 0.9302 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2129 - accuracy: 0.9370 - val_loss: 0.2427 - val_accuracy: 0.9308 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2109 - accuracy: 0.9372 - val_loss: 0.2381 - val_accuracy: 0.9321 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.2110 - accuracy: 0.9365 - val_loss: 0.2326 - val_accuracy: 0.9349 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.2073 - accuracy: 0.9378 - val_loss: 0.2431 - val_accuracy: 0.9286 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2044 - accuracy: 0.9392 - val_loss: 0.2331 - val_accuracy: 0.9314 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2011 - accuracy: 0.9394 - val_loss: 0.2293 - val_accuracy: 0.9336 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2002 - accuracy: 0.9415 - val_loss: 0.2319 - val_accuracy: 0.9333 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1991 - accuracy: 0.9404 - val_loss: 0.2243 - val_accuracy: 0.9358 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.1959 - accuracy: 0.9402 - val_loss: 0.2334 - val_accuracy: 0.9324 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1919 - accuracy: 0.9424 - val_loss: 0.2305 - val_accuracy: 0.9352 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1931 - accuracy: 0.9403 - val_loss: 0.2230 - val_accuracy: 0.9358 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.1912 - accuracy: 0.9423 - val_loss: 0.2274 - val_accuracy: 0.9337 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1891 - accuracy: 0.9427 - val_loss: 0.2213 - val_accuracy: 0.9366 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1891 - accuracy: 0.9415 - val_loss: 0.2293 - val_accuracy: 0.9352 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1858 - accuracy: 0.9435 - val_loss: 0.2380 - val_accuracy: 0.9293 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 0.1858 - accuracy: 0.9429 - val_loss: 0.2275 - val_accuracy: 0.9349 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 1.5000 - accuracy: 0.4633 - val_loss: 0.8104 - val_accuracy: 0.7399 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6102 - accuracy: 0.8275 - val_loss: 0.5046 - val_accuracy: 0.8586 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4696 - accuracy: 0.8685 - val_loss: 0.4506 - val_accuracy: 0.8728 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4267 - accuracy: 0.8792 - val_loss: 0.4110 - val_accuracy: 0.8764 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4020 - accuracy: 0.8849 - val_loss: 0.4088 - val_accuracy: 0.8830 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3855 - accuracy: 0.8899 - val_loss: 0.3814 - val_accuracy: 0.8877 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3762 - accuracy: 0.8917 - val_loss: 0.3750 - val_accuracy: 0.8896 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3648 - accuracy: 0.8949 - val_loss: 0.3694 - val_accuracy: 0.8889 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3597 - accuracy: 0.8953 - val_loss: 0.3751 - val_accuracy: 0.8867 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3516 - accuracy: 0.8969 - val_loss: 0.3556 - val_accuracy: 0.8946 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3369 - accuracy: 0.9015 - val_loss: 0.3397 - val_accuracy: 0.9014 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3222 - accuracy: 0.9066 - val_loss: 0.3393 - val_accuracy: 0.9007 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3117 - accuracy: 0.9090 - val_loss: 0.3240 - val_accuracy: 0.9007 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3006 - accuracy: 0.9120 - val_loss: 0.3236 - val_accuracy: 0.9036 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2960 - accuracy: 0.9131 - val_loss: 0.3104 - val_accuracy: 0.9098 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2844 - accuracy: 0.9163 - val_loss: 0.3182 - val_accuracy: 0.9064 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2769 - accuracy: 0.9173 - val_loss: 0.2878 - val_accuracy: 0.9123 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2718 - accuracy: 0.9192 - val_loss: 0.2876 - val_accuracy: 0.9144 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2644 - accuracy: 0.9213 - val_loss: 0.2895 - val_accuracy: 0.9140 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2625 - accuracy: 0.9214 - val_loss: 0.2954 - val_accuracy: 0.9093 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2561 - accuracy: 0.9243 - val_loss: 0.2798 - val_accuracy: 0.9168 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2546 - accuracy: 0.9241 - val_loss: 0.2889 - val_accuracy: 0.9119 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2484 - accuracy: 0.9255 - val_loss: 0.2627 - val_accuracy: 0.9202 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2441 - accuracy: 0.9268 - val_loss: 0.2684 - val_accuracy: 0.9183 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2435 - accuracy: 0.9277 - val_loss: 0.2712 - val_accuracy: 0.9165 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2377 - accuracy: 0.9292 - val_loss: 0.2810 - val_accuracy: 0.9139 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.2501 - accuracy: 0.1499 - val_loss: 2.2016 - val_accuracy: 0.1678 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.1866 - accuracy: 0.1895 - val_loss: 2.1665 - val_accuracy: 0.2017 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.1543 - accuracy: 0.2142 - val_loss: 2.1383 - val_accuracy: 0.2206 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.1337 - accuracy: 0.2210 - val_loss: 2.1459 - val_accuracy: 0.2081 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 2.1218 - accuracy: 0.2229 - val_loss: 2.1167 - val_accuracy: 0.2295 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.1116 - accuracy: 0.2310 - val_loss: 2.1275 - val_accuracy: 0.2397 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 2.1054 - accuracy: 0.2328 - val_loss: 2.0937 - val_accuracy: 0.2313 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.1002 - accuracy: 0.2390 - val_loss: 2.1164 - val_accuracy: 0.2352 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.0945 - accuracy: 0.2473 - val_loss: 2.0824 - val_accuracy: 0.2293 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.0881 - accuracy: 0.2526 - val_loss: 2.0827 - val_accuracy: 0.2432 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 2.0869 - accuracy: 0.2505 - val_loss: 2.0938 - val_accuracy: 0.2503 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 2.0841 - accuracy: 0.2548 - val_loss: 2.1098 - val_accuracy: 0.1941 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 2.0649 - accuracy: 0.2670 - val_loss: 1.9404 - val_accuracy: 0.3044 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 1.8874 - accuracy: 0.3298 - val_loss: 1.8553 - val_accuracy: 0.3492 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.8256 - accuracy: 0.3577 - val_loss: 1.8022 - val_accuracy: 0.3697 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7960 - accuracy: 0.3689 - val_loss: 1.7799 - val_accuracy: 0.3761 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7767 - accuracy: 0.3765 - val_loss: 1.7652 - val_accuracy: 0.3808 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7614 - accuracy: 0.3817 - val_loss: 1.7465 - val_accuracy: 0.3867 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7455 - accuracy: 0.3885 - val_loss: 1.7329 - val_accuracy: 0.3927 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7341 - accuracy: 0.3895 - val_loss: 1.7244 - val_accuracy: 0.3923 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 1.7266 - accuracy: 0.3943 - val_loss: 1.7213 - val_accuracy: 0.3961 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7223 - accuracy: 0.3938 - val_loss: 1.7097 - val_accuracy: 0.3980 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7156 - accuracy: 0.3962 - val_loss: 1.7108 - val_accuracy: 0.3977 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7096 - accuracy: 0.3987 - val_loss: 1.7030 - val_accuracy: 0.4027 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7068 - accuracy: 0.3984 - val_loss: 1.6984 - val_accuracy: 0.4002 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7040 - accuracy: 0.4006 - val_loss: 1.6950 - val_accuracy: 0.4058 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.7008 - accuracy: 0.3989 - val_loss: 1.6947 - val_accuracy: 0.4023 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 1.7002 - accuracy: 0.4002 - val_loss: 1.6951 - val_accuracy: 0.4013 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.6950 - accuracy: 0.4010 - val_loss: 1.6882 - val_accuracy: 0.4039 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.6932 - accuracy: 0.4018 - val_loss: 1.6866 - val_accuracy: 0.4051 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 1.6901 - accuracy: 0.4038 - val_loss: 1.6895 - val_accuracy: 0.4024 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.6922 - accuracy: 0.4022 - val_loss: 1.6808 - val_accuracy: 0.4077 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 1.6884 - accuracy: 0.4033 - val_loss: 1.6852 - val_accuracy: 0.4012 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 1.6868 - accuracy: 0.4044 - val_loss: 1.6879 - val_accuracy: 0.4025 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 10s 25ms/step - loss: 1.6859 - accuracy: 0.4043 - val_loss: 1.6867 - val_accuracy: 0.3999 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 16s 41ms/step - loss: 2.2994 - accuracy: 0.1281 - val_loss: 2.2821 - val_accuracy: 0.1504 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 16s 41ms/step - loss: 2.2640 - accuracy: 0.1793 - val_loss: 2.2436 - val_accuracy: 0.2013 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.2182 - accuracy: 0.2076 - val_loss: 2.1948 - val_accuracy: 0.2130 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1675 - accuracy: 0.2175 - val_loss: 2.1481 - val_accuracy: 0.2241 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1264 - accuracy: 0.2258 - val_loss: 2.1167 - val_accuracy: 0.2272 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 2.0976 - accuracy: 0.2301 - val_loss: 2.0913 - val_accuracy: 0.2342 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 2.0715 - accuracy: 0.2392 - val_loss: 2.0686 - val_accuracy: 0.2425 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 2.0496 - accuracy: 0.2479 - val_loss: 2.0488 - val_accuracy: 0.2477 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.0316 - accuracy: 0.2560 - val_loss: 2.0339 - val_accuracy: 0.2555 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 2.0157 - accuracy: 0.2650 - val_loss: 2.0173 - val_accuracy: 0.2652 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.0031 - accuracy: 0.2720 - val_loss: 2.0056 - val_accuracy: 0.2733 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9936 - accuracy: 0.2757 - val_loss: 1.9997 - val_accuracy: 0.2748 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 16s 41ms/step - loss: 1.9866 - accuracy: 0.2782 - val_loss: 1.9931 - val_accuracy: 0.2821 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9809 - accuracy: 0.2809 - val_loss: 1.9861 - val_accuracy: 0.2816 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9768 - accuracy: 0.2826 - val_loss: 1.9826 - val_accuracy: 0.2829 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9732 - accuracy: 0.2826 - val_loss: 1.9811 - val_accuracy: 0.2820 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9700 - accuracy: 0.2844 - val_loss: 1.9789 - val_accuracy: 0.2803 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9677 - accuracy: 0.2852 - val_loss: 1.9752 - val_accuracy: 0.2852 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9667 - accuracy: 0.2873 - val_loss: 1.9765 - val_accuracy: 0.2857 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9647 - accuracy: 0.2865 - val_loss: 1.9707 - val_accuracy: 0.2882 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9631 - accuracy: 0.2879 - val_loss: 1.9683 - val_accuracy: 0.2888 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9614 - accuracy: 0.2892 - val_loss: 1.9686 - val_accuracy: 0.2923 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9603 - accuracy: 0.2889 - val_loss: 1.9662 - val_accuracy: 0.2910 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9594 - accuracy: 0.2898 - val_loss: 1.9664 - val_accuracy: 0.2890 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9581 - accuracy: 0.2900 - val_loss: 1.9653 - val_accuracy: 0.2869 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 1.9568 - accuracy: 0.2905 - val_loss: 1.9644 - val_accuracy: 0.2912 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 1.9564 - accuracy: 0.2903 - val_loss: 1.9609 - val_accuracy: 0.2898 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9551 - accuracy: 0.2907 - val_loss: 1.9597 - val_accuracy: 0.2916 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9547 - accuracy: 0.2907 - val_loss: 1.9606 - val_accuracy: 0.2876 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9536 - accuracy: 0.2905 - val_loss: 1.9607 - val_accuracy: 0.2850 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9537 - accuracy: 0.2906 - val_loss: 1.9582 - val_accuracy: 0.2907 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9527 - accuracy: 0.2916 - val_loss: 1.9566 - val_accuracy: 0.2898 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9516 - accuracy: 0.2923 - val_loss: 1.9567 - val_accuracy: 0.2912 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9515 - accuracy: 0.2924 - val_loss: 1.9560 - val_accuracy: 0.2943 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9515 - accuracy: 0.2921 - val_loss: 1.9602 - val_accuracy: 0.2872 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9511 - accuracy: 0.2907 - val_loss: 1.9596 - val_accuracy: 0.2901 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9505 - accuracy: 0.2920 - val_loss: 1.9544 - val_accuracy: 0.2913 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9501 - accuracy: 0.2918 - val_loss: 1.9544 - val_accuracy: 0.2926 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9500 - accuracy: 0.2913 - val_loss: 1.9541 - val_accuracy: 0.2965 - lr: 0.0100\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9484 - accuracy: 0.2924 - val_loss: 1.9524 - val_accuracy: 0.2959 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9482 - accuracy: 0.2916 - val_loss: 1.9521 - val_accuracy: 0.2913 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9471 - accuracy: 0.2909 - val_loss: 1.9514 - val_accuracy: 0.2943 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 1.9459 - accuracy: 0.2919 - val_loss: 1.9496 - val_accuracy: 0.2933 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 1.9453 - accuracy: 0.2920 - val_loss: 1.9481 - val_accuracy: 0.2906 - lr: 0.0100\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.9428 - accuracy: 0.2914 - val_loss: 1.9496 - val_accuracy: 0.2910 - lr: 0.0100\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9415 - accuracy: 0.2908 - val_loss: 1.9463 - val_accuracy: 0.2889 - lr: 0.0100\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9396 - accuracy: 0.2891 - val_loss: 1.9433 - val_accuracy: 0.2882 - lr: 0.0100\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9371 - accuracy: 0.2900 - val_loss: 1.9415 - val_accuracy: 0.2891 - lr: 0.0100\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9353 - accuracy: 0.2896 - val_loss: 1.9395 - val_accuracy: 0.2896 - lr: 0.0100\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9329 - accuracy: 0.2887 - val_loss: 1.9380 - val_accuracy: 0.2863 - lr: 0.0100\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9302 - accuracy: 0.2882 - val_loss: 1.9331 - val_accuracy: 0.2877 - lr: 0.0100\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 52/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9273 - accuracy: 0.2882 - val_loss: 1.9307 - val_accuracy: 0.2892 - lr: 0.0100\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 53/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 1.9244 - accuracy: 0.2893 - val_loss: 1.9266 - val_accuracy: 0.2842 - lr: 0.0100\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 54/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9217 - accuracy: 0.2879 - val_loss: 1.9238 - val_accuracy: 0.2879 - lr: 0.0100\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 55/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9198 - accuracy: 0.2892 - val_loss: 1.9244 - val_accuracy: 0.2867 - lr: 0.0100\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 56/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9171 - accuracy: 0.2886 - val_loss: 1.9211 - val_accuracy: 0.2867 - lr: 0.0100\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 57/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9156 - accuracy: 0.2895 - val_loss: 1.9167 - val_accuracy: 0.2895 - lr: 0.0100\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 58/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9138 - accuracy: 0.2902 - val_loss: 1.9153 - val_accuracy: 0.2903 - lr: 0.0100\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 59/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9119 - accuracy: 0.2901 - val_loss: 1.9120 - val_accuracy: 0.2898 - lr: 0.0100\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 60/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9105 - accuracy: 0.2909 - val_loss: 1.9122 - val_accuracy: 0.2920 - lr: 0.0100\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 61/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9082 - accuracy: 0.2904 - val_loss: 1.9104 - val_accuracy: 0.2882 - lr: 0.0100\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 62/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9071 - accuracy: 0.2922 - val_loss: 1.9068 - val_accuracy: 0.2923 - lr: 0.0100\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 63/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.9049 - accuracy: 0.2918 - val_loss: 1.9070 - val_accuracy: 0.2923 - lr: 0.0100\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 64/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.9017 - accuracy: 0.2925 - val_loss: 1.9040 - val_accuracy: 0.2927 - lr: 0.0100\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 65/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8999 - accuracy: 0.2930 - val_loss: 1.9032 - val_accuracy: 0.2912 - lr: 0.0100\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 66/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8975 - accuracy: 0.2934 - val_loss: 1.8992 - val_accuracy: 0.2923 - lr: 0.0100\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 67/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8963 - accuracy: 0.2949 - val_loss: 1.8981 - val_accuracy: 0.2908 - lr: 0.0100\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 68/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8951 - accuracy: 0.2954 - val_loss: 1.8972 - val_accuracy: 0.2968 - lr: 0.0100\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 69/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8933 - accuracy: 0.2958 - val_loss: 1.8987 - val_accuracy: 0.2981 - lr: 0.0100\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 70/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8932 - accuracy: 0.2965 - val_loss: 1.8970 - val_accuracy: 0.2892 - lr: 0.0100\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 71/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8920 - accuracy: 0.2969 - val_loss: 1.8986 - val_accuracy: 0.2948 - lr: 0.0100\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 72/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8908 - accuracy: 0.2967 - val_loss: 1.8974 - val_accuracy: 0.2980 - lr: 0.0100\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 73/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8901 - accuracy: 0.2974 - val_loss: 1.8932 - val_accuracy: 0.2986 - lr: 0.0100\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 74/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8901 - accuracy: 0.2978 - val_loss: 1.8906 - val_accuracy: 0.2959 - lr: 0.0100\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 75/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8887 - accuracy: 0.2979 - val_loss: 1.8905 - val_accuracy: 0.2970 - lr: 0.0100\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 76/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8882 - accuracy: 0.2981 - val_loss: 1.8908 - val_accuracy: 0.2993 - lr: 0.0100\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 77/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8877 - accuracy: 0.2993 - val_loss: 1.8900 - val_accuracy: 0.3007 - lr: 0.0100\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 78/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.8869 - accuracy: 0.2985 - val_loss: 1.8897 - val_accuracy: 0.2999 - lr: 0.0100\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 79/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 1.8864 - accuracy: 0.2988 - val_loss: 1.8882 - val_accuracy: 0.2996 - lr: 0.0100\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 80/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8861 - accuracy: 0.2988 - val_loss: 1.8878 - val_accuracy: 0.2989 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.2920 - accuracy: 0.1216 - val_loss: 2.2496 - val_accuracy: 0.1637 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.2294 - accuracy: 0.1805 - val_loss: 2.2065 - val_accuracy: 0.2048 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.1942 - accuracy: 0.2192 - val_loss: 2.1782 - val_accuracy: 0.2304 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.1701 - accuracy: 0.2398 - val_loss: 2.1573 - val_accuracy: 0.2466 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.1525 - accuracy: 0.2467 - val_loss: 2.1420 - val_accuracy: 0.2494 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.1387 - accuracy: 0.2488 - val_loss: 2.1299 - val_accuracy: 0.2546 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.1282 - accuracy: 0.2511 - val_loss: 2.1205 - val_accuracy: 0.2570 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.1196 - accuracy: 0.2532 - val_loss: 2.1128 - val_accuracy: 0.2531 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.1124 - accuracy: 0.2549 - val_loss: 2.1064 - val_accuracy: 0.2598 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.1065 - accuracy: 0.2555 - val_loss: 2.1014 - val_accuracy: 0.2548 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.1013 - accuracy: 0.2556 - val_loss: 2.0964 - val_accuracy: 0.2605 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0970 - accuracy: 0.2565 - val_loss: 2.0927 - val_accuracy: 0.2618 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.0931 - accuracy: 0.2575 - val_loss: 2.0892 - val_accuracy: 0.2567 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0898 - accuracy: 0.2566 - val_loss: 2.0860 - val_accuracy: 0.2603 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.0868 - accuracy: 0.2583 - val_loss: 2.0831 - val_accuracy: 0.2605 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.0841 - accuracy: 0.2590 - val_loss: 2.0806 - val_accuracy: 0.2618 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0816 - accuracy: 0.2596 - val_loss: 2.0789 - val_accuracy: 0.2592 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0795 - accuracy: 0.2601 - val_loss: 2.0767 - val_accuracy: 0.2610 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0774 - accuracy: 0.2603 - val_loss: 2.0745 - val_accuracy: 0.2620 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0756 - accuracy: 0.2614 - val_loss: 2.0732 - val_accuracy: 0.2645 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0738 - accuracy: 0.2616 - val_loss: 2.0712 - val_accuracy: 0.2643 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.0722 - accuracy: 0.2611 - val_loss: 2.0703 - val_accuracy: 0.2635 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0708 - accuracy: 0.2630 - val_loss: 2.0684 - val_accuracy: 0.2630 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0694 - accuracy: 0.2628 - val_loss: 2.0674 - val_accuracy: 0.2639 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.0683 - accuracy: 0.2622 - val_loss: 2.0662 - val_accuracy: 0.2647 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0670 - accuracy: 0.2634 - val_loss: 2.0651 - val_accuracy: 0.2633 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0658 - accuracy: 0.2633 - val_loss: 2.0644 - val_accuracy: 0.2633 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0648 - accuracy: 0.2637 - val_loss: 2.0630 - val_accuracy: 0.2647 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0639 - accuracy: 0.2633 - val_loss: 2.0622 - val_accuracy: 0.2659 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0628 - accuracy: 0.2658 - val_loss: 2.0610 - val_accuracy: 0.2676 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0618 - accuracy: 0.2652 - val_loss: 2.0602 - val_accuracy: 0.2662 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0610 - accuracy: 0.2657 - val_loss: 2.0597 - val_accuracy: 0.2656 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0602 - accuracy: 0.2657 - val_loss: 2.0586 - val_accuracy: 0.2652 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0593 - accuracy: 0.2662 - val_loss: 2.0580 - val_accuracy: 0.2673 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0586 - accuracy: 0.2674 - val_loss: 2.0572 - val_accuracy: 0.2652 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0579 - accuracy: 0.2668 - val_loss: 2.0568 - val_accuracy: 0.2677 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0571 - accuracy: 0.2664 - val_loss: 2.0561 - val_accuracy: 0.2681 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0564 - accuracy: 0.2661 - val_loss: 2.0553 - val_accuracy: 0.2676 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0558 - accuracy: 0.2672 - val_loss: 2.0551 - val_accuracy: 0.2673 - lr: 0.0100\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0552 - accuracy: 0.2673 - val_loss: 2.0544 - val_accuracy: 0.2679 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0545 - accuracy: 0.2677 - val_loss: 2.0535 - val_accuracy: 0.2683 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0540 - accuracy: 0.2679 - val_loss: 2.0531 - val_accuracy: 0.2693 - lr: 0.0100\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0534 - accuracy: 0.2695 - val_loss: 2.0523 - val_accuracy: 0.2693 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0528 - accuracy: 0.2680 - val_loss: 2.0522 - val_accuracy: 0.2695 - lr: 0.0100\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0523 - accuracy: 0.2698 - val_loss: 2.0514 - val_accuracy: 0.2677 - lr: 0.0100\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0517 - accuracy: 0.2686 - val_loss: 2.0514 - val_accuracy: 0.2718 - lr: 0.0100\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0512 - accuracy: 0.2689 - val_loss: 2.0505 - val_accuracy: 0.2685 - lr: 0.0100\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0507 - accuracy: 0.2684 - val_loss: 2.0500 - val_accuracy: 0.2688 - lr: 0.0100\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.0503 - accuracy: 0.2701 - val_loss: 2.0496 - val_accuracy: 0.2717 - lr: 0.0100\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0498 - accuracy: 0.2692 - val_loss: 2.0492 - val_accuracy: 0.2693 - lr: 0.0100\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0493 - accuracy: 0.2700 - val_loss: 2.0485 - val_accuracy: 0.2699 - lr: 0.0100\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 52/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0489 - accuracy: 0.2698 - val_loss: 2.0486 - val_accuracy: 0.2679 - lr: 0.0100\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 53/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.0483 - accuracy: 0.2706 - val_loss: 2.0480 - val_accuracy: 0.2667 - lr: 0.0100\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 54/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0480 - accuracy: 0.2704 - val_loss: 2.0473 - val_accuracy: 0.2706 - lr: 0.0100\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 55/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0474 - accuracy: 0.2707 - val_loss: 2.0475 - val_accuracy: 0.2685 - lr: 0.0100\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 56/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0472 - accuracy: 0.2703 - val_loss: 2.0468 - val_accuracy: 0.2720 - lr: 0.0100\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 57/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0467 - accuracy: 0.2708 - val_loss: 2.0460 - val_accuracy: 0.2716 - lr: 0.0100\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 58/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0463 - accuracy: 0.2716 - val_loss: 2.0463 - val_accuracy: 0.2707 - lr: 0.0100\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 59/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0459 - accuracy: 0.2723 - val_loss: 2.0456 - val_accuracy: 0.2707 - lr: 0.0100\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 60/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0455 - accuracy: 0.2718 - val_loss: 2.0452 - val_accuracy: 0.2698 - lr: 0.0100\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 61/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0451 - accuracy: 0.2722 - val_loss: 2.0454 - val_accuracy: 0.2691 - lr: 0.0100\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 62/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0447 - accuracy: 0.2714 - val_loss: 2.0449 - val_accuracy: 0.2682 - lr: 0.0100\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 63/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0445 - accuracy: 0.2722 - val_loss: 2.0446 - val_accuracy: 0.2689 - lr: 0.0100\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 64/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0441 - accuracy: 0.2716 - val_loss: 2.0441 - val_accuracy: 0.2718 - lr: 0.0100\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 65/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0436 - accuracy: 0.2726 - val_loss: 2.0434 - val_accuracy: 0.2719 - lr: 0.0100\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 66/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0434 - accuracy: 0.2718 - val_loss: 2.0434 - val_accuracy: 0.2718 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 67/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0430 - accuracy: 0.2732 - val_loss: 2.0432 - val_accuracy: 0.2706 - lr: 0.0100\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 68/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0427 - accuracy: 0.2723 - val_loss: 2.0426 - val_accuracy: 0.2718 - lr: 0.0100\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 69/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0424 - accuracy: 0.2728 - val_loss: 2.0422 - val_accuracy: 0.2716 - lr: 0.0100\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 70/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0422 - accuracy: 0.2719 - val_loss: 2.0420 - val_accuracy: 0.2738 - lr: 0.0100\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 71/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0417 - accuracy: 0.2737 - val_loss: 2.0418 - val_accuracy: 0.2739 - lr: 0.0100\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 72/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0414 - accuracy: 0.2727 - val_loss: 2.0413 - val_accuracy: 0.2737 - lr: 0.0100\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 73/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0411 - accuracy: 0.2731 - val_loss: 2.0411 - val_accuracy: 0.2736 - lr: 0.0100\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 74/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0407 - accuracy: 0.2739 - val_loss: 2.0414 - val_accuracy: 0.2734 - lr: 0.0100\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 75/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0406 - accuracy: 0.2737 - val_loss: 2.0410 - val_accuracy: 0.2727 - lr: 0.0100\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 76/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0402 - accuracy: 0.2730 - val_loss: 2.0407 - val_accuracy: 0.2720 - lr: 0.0100\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 77/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0400 - accuracy: 0.2734 - val_loss: 2.0406 - val_accuracy: 0.2735 - lr: 0.0100\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 78/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0397 - accuracy: 0.2734 - val_loss: 2.0400 - val_accuracy: 0.2718 - lr: 0.0100\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 79/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0395 - accuracy: 0.2738 - val_loss: 2.0397 - val_accuracy: 0.2758 - lr: 0.0100\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 80/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0392 - accuracy: 0.2750 - val_loss: 2.0393 - val_accuracy: 0.2748 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4086 - accuracy: 0.0931 - val_loss: 2.4111 - val_accuracy: 0.0918 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4086 - accuracy: 0.0931 - val_loss: 2.4111 - val_accuracy: 0.0918 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4086 - accuracy: 0.0931 - val_loss: 2.4111 - val_accuracy: 0.0918 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4086 - accuracy: 0.0931 - val_loss: 2.4111 - val_accuracy: 0.0918 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 1.4732 - accuracy: 0.4400 - val_loss: 1.0897 - val_accuracy: 0.6070 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.7346 - accuracy: 0.7603 - val_loss: 0.6029 - val_accuracy: 0.7975 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.4686 - accuracy: 0.8630 - val_loss: 0.4042 - val_accuracy: 0.8837 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3753 - accuracy: 0.8958 - val_loss: 0.4015 - val_accuracy: 0.8767 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3319 - accuracy: 0.9061 - val_loss: 0.3013 - val_accuracy: 0.9169 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2989 - accuracy: 0.9159 - val_loss: 0.2857 - val_accuracy: 0.9182 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2810 - accuracy: 0.9205 - val_loss: 0.2791 - val_accuracy: 0.9212 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2640 - accuracy: 0.9255 - val_loss: 0.2765 - val_accuracy: 0.9222 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2601 - accuracy: 0.9258 - val_loss: 0.2564 - val_accuracy: 0.9267 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2460 - accuracy: 0.9297 - val_loss: 0.2403 - val_accuracy: 0.9316 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2341 - accuracy: 0.9327 - val_loss: 0.2344 - val_accuracy: 0.9324 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2324 - accuracy: 0.9313 - val_loss: 0.2317 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2248 - accuracy: 0.9345 - val_loss: 0.2272 - val_accuracy: 0.9308 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2223 - accuracy: 0.9340 - val_loss: 0.2186 - val_accuracy: 0.9354 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2167 - accuracy: 0.9367 - val_loss: 0.2290 - val_accuracy: 0.9318 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2096 - accuracy: 0.9380 - val_loss: 0.2164 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2063 - accuracy: 0.9386 - val_loss: 0.2214 - val_accuracy: 0.9353 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2006 - accuracy: 0.9399 - val_loss: 0.2120 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2016 - accuracy: 0.9410 - val_loss: 0.2151 - val_accuracy: 0.9387 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.1991 - accuracy: 0.9412 - val_loss: 0.2147 - val_accuracy: 0.9377 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1970 - accuracy: 0.9410 - val_loss: 0.2137 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.3013 - accuracy: 0.5752 - val_loss: 0.6457 - val_accuracy: 0.8157 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5089 - accuracy: 0.8597 - val_loss: 0.4284 - val_accuracy: 0.8863 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3987 - accuracy: 0.8911 - val_loss: 0.3906 - val_accuracy: 0.8967 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3516 - accuracy: 0.9051 - val_loss: 0.3463 - val_accuracy: 0.9104 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3286 - accuracy: 0.9121 - val_loss: 0.3525 - val_accuracy: 0.9061 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3178 - accuracy: 0.9145 - val_loss: 0.3549 - val_accuracy: 0.9031 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2928 - accuracy: 0.9209 - val_loss: 0.3330 - val_accuracy: 0.9128 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2872 - accuracy: 0.9218 - val_loss: 0.3261 - val_accuracy: 0.9073 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2769 - accuracy: 0.9259 - val_loss: 0.3228 - val_accuracy: 0.9133 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2714 - accuracy: 0.9254 - val_loss: 0.3377 - val_accuracy: 0.9093 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2611 - accuracy: 0.9287 - val_loss: 0.2941 - val_accuracy: 0.9217 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2559 - accuracy: 0.9289 - val_loss: 0.3026 - val_accuracy: 0.9179 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2494 - accuracy: 0.9304 - val_loss: 0.3203 - val_accuracy: 0.9105 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2459 - accuracy: 0.9324 - val_loss: 0.2801 - val_accuracy: 0.9225 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2418 - accuracy: 0.9318 - val_loss: 0.2695 - val_accuracy: 0.9248 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2346 - accuracy: 0.9331 - val_loss: 0.2704 - val_accuracy: 0.9269 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2354 - accuracy: 0.9343 - val_loss: 0.2898 - val_accuracy: 0.9220 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2315 - accuracy: 0.9346 - val_loss: 0.2941 - val_accuracy: 0.9178 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.3174 - accuracy: 0.1604 - val_loss: 2.2469 - val_accuracy: 0.1729 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.2301 - accuracy: 0.1830 - val_loss: 2.2094 - val_accuracy: 0.1965 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.2037 - accuracy: 0.1960 - val_loss: 2.1904 - val_accuracy: 0.2074 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 2.1834 - accuracy: 0.2007 - val_loss: 2.1757 - val_accuracy: 0.2082 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.1731 - accuracy: 0.2016 - val_loss: 2.1623 - val_accuracy: 0.2089 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.1625 - accuracy: 0.2059 - val_loss: 2.1513 - val_accuracy: 0.2170 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 2.1539 - accuracy: 0.2092 - val_loss: 2.1453 - val_accuracy: 0.2192 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1483 - accuracy: 0.2113 - val_loss: 2.1357 - val_accuracy: 0.2221 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 2.1428 - accuracy: 0.2100 - val_loss: 2.1364 - val_accuracy: 0.2200 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1387 - accuracy: 0.2089 - val_loss: 2.1325 - val_accuracy: 0.2163 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1374 - accuracy: 0.2100 - val_loss: 2.1282 - val_accuracy: 0.2150 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1325 - accuracy: 0.2097 - val_loss: 2.1252 - val_accuracy: 0.2172 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1300 - accuracy: 0.2077 - val_loss: 2.1248 - val_accuracy: 0.2164 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 2.1275 - accuracy: 0.2110 - val_loss: 2.1194 - val_accuracy: 0.2150 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1264 - accuracy: 0.2087 - val_loss: 2.1164 - val_accuracy: 0.2192 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1217 - accuracy: 0.2119 - val_loss: 2.1153 - val_accuracy: 0.2173 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.1199 - accuracy: 0.2089 - val_loss: 2.1183 - val_accuracy: 0.2195 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 2.1188 - accuracy: 0.2126 - val_loss: 2.1110 - val_accuracy: 0.2173 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 2.1158 - accuracy: 0.2125 - val_loss: 2.1095 - val_accuracy: 0.2210 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1156 - accuracy: 0.2127 - val_loss: 2.1077 - val_accuracy: 0.2187 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1129 - accuracy: 0.2122 - val_loss: 2.1066 - val_accuracy: 0.2192 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1117 - accuracy: 0.2129 - val_loss: 2.1061 - val_accuracy: 0.2211 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.1100 - accuracy: 0.2124 - val_loss: 2.1052 - val_accuracy: 0.2188 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 2.1094 - accuracy: 0.2128 - val_loss: 2.1014 - val_accuracy: 0.2203 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.1064 - accuracy: 0.2116 - val_loss: 2.0986 - val_accuracy: 0.2227 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1036 - accuracy: 0.2137 - val_loss: 2.0987 - val_accuracy: 0.2225 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 2.1021 - accuracy: 0.2151 - val_loss: 2.0973 - val_accuracy: 0.2194 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.1013 - accuracy: 0.2131 - val_loss: 2.0930 - val_accuracy: 0.2201 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0996 - accuracy: 0.2169 - val_loss: 2.0931 - val_accuracy: 0.2193 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 2.0992 - accuracy: 0.2119 - val_loss: 2.0926 - val_accuracy: 0.2184 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0978 - accuracy: 0.2136 - val_loss: 2.0940 - val_accuracy: 0.2187 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0988 - accuracy: 0.2159 - val_loss: 2.0925 - val_accuracy: 0.2181 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0975 - accuracy: 0.2153 - val_loss: 2.0913 - val_accuracy: 0.2215 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0976 - accuracy: 0.2160 - val_loss: 2.0915 - val_accuracy: 0.2238 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0965 - accuracy: 0.2157 - val_loss: 2.0889 - val_accuracy: 0.2183 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 2.0965 - accuracy: 0.2133 - val_loss: 2.0919 - val_accuracy: 0.2227 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0948 - accuracy: 0.2167 - val_loss: 2.0875 - val_accuracy: 0.2205 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0952 - accuracy: 0.2160 - val_loss: 2.0873 - val_accuracy: 0.2208 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0948 - accuracy: 0.2146 - val_loss: 2.0863 - val_accuracy: 0.2210 - lr: 0.0100\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 2.0928 - accuracy: 0.2168 - val_loss: 2.0868 - val_accuracy: 0.2173 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0947 - accuracy: 0.2145 - val_loss: 2.0873 - val_accuracy: 0.2213 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0940 - accuracy: 0.2181 - val_loss: 2.0861 - val_accuracy: 0.2222 - lr: 0.0100\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0926 - accuracy: 0.2173 - val_loss: 2.0851 - val_accuracy: 0.2219 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0923 - accuracy: 0.2154 - val_loss: 2.0842 - val_accuracy: 0.2191 - lr: 0.0100\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0926 - accuracy: 0.2175 - val_loss: 2.0849 - val_accuracy: 0.2181 - lr: 0.0100\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0928 - accuracy: 0.2160 - val_loss: 2.0838 - val_accuracy: 0.2202 - lr: 0.0100\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0924 - accuracy: 0.2168 - val_loss: 2.0831 - val_accuracy: 0.2210 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0903 - accuracy: 0.2166 - val_loss: 2.0857 - val_accuracy: 0.2198 - lr: 0.0100\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0906 - accuracy: 0.2164 - val_loss: 2.0825 - val_accuracy: 0.2237 - lr: 0.0100\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0926 - accuracy: 0.2171 - val_loss: 2.0823 - val_accuracy: 0.2235 - lr: 0.0100\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 2.0913 - accuracy: 0.2159 - val_loss: 2.0827 - val_accuracy: 0.2208 - lr: 0.0100\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 52/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0920 - accuracy: 0.2169 - val_loss: 2.0832 - val_accuracy: 0.2211 - lr: 0.0100\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 53/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.0897 - accuracy: 0.2180 - val_loss: 2.0825 - val_accuracy: 0.2225 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 2.1401 - accuracy: 0.2192 - val_loss: 2.0309 - val_accuracy: 0.2899 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.9508 - accuracy: 0.3057 - val_loss: 1.8932 - val_accuracy: 0.3269 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.8353 - accuracy: 0.3449 - val_loss: 1.8374 - val_accuracy: 0.3503 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.7471 - accuracy: 0.3761 - val_loss: 1.8076 - val_accuracy: 0.3593 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 1.7007 - accuracy: 0.3900 - val_loss: 1.7337 - val_accuracy: 0.3861 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.6782 - accuracy: 0.3984 - val_loss: 1.6654 - val_accuracy: 0.4038 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.6643 - accuracy: 0.4024 - val_loss: 1.6425 - val_accuracy: 0.4157 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.6592 - accuracy: 0.4033 - val_loss: 1.6789 - val_accuracy: 0.4026 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.6516 - accuracy: 0.4066 - val_loss: 1.6667 - val_accuracy: 0.4046 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.6476 - accuracy: 0.4092 - val_loss: 1.6370 - val_accuracy: 0.4155 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 1.6433 - accuracy: 0.4090 - val_loss: 1.6261 - val_accuracy: 0.4186 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.6395 - accuracy: 0.4103 - val_loss: 1.6208 - val_accuracy: 0.4204 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.6344 - accuracy: 0.4138 - val_loss: 1.6282 - val_accuracy: 0.4174 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.6319 - accuracy: 0.4145 - val_loss: 1.6441 - val_accuracy: 0.4122 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 1.6319 - accuracy: 0.4161 - val_loss: 1.6362 - val_accuracy: 0.4212 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 2.2832 - accuracy: 0.1282 - val_loss: 2.2464 - val_accuracy: 0.1597 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.1952 - accuracy: 0.1680 - val_loss: 2.1561 - val_accuracy: 0.1824 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 2.1252 - accuracy: 0.2071 - val_loss: 2.1049 - val_accuracy: 0.1982 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 2.0806 - accuracy: 0.2095 - val_loss: 2.0767 - val_accuracy: 0.2013 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 2.0577 - accuracy: 0.2160 - val_loss: 2.0623 - val_accuracy: 0.2111 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 2.0462 - accuracy: 0.2280 - val_loss: 2.0553 - val_accuracy: 0.2262 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 2.0373 - accuracy: 0.2432 - val_loss: 2.0461 - val_accuracy: 0.2361 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 26s 71ms/step - loss: 2.0307 - accuracy: 0.2508 - val_loss: 2.0414 - val_accuracy: 0.2564 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 2.0243 - accuracy: 0.2654 - val_loss: 2.0365 - val_accuracy: 0.2615 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 2.0191 - accuracy: 0.2753 - val_loss: 2.0312 - val_accuracy: 0.2772 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 2.0136 - accuracy: 0.2828 - val_loss: 2.0279 - val_accuracy: 0.2771 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 2.0096 - accuracy: 0.2854 - val_loss: 2.0258 - val_accuracy: 0.2746 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 2.0065 - accuracy: 0.2870 - val_loss: 2.0311 - val_accuracy: 0.2850 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 21s 56ms/step - loss: 2.0030 - accuracy: 0.2920 - val_loss: 2.0198 - val_accuracy: 0.2888 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 1.9999 - accuracy: 0.2937 - val_loss: 2.0138 - val_accuracy: 0.2915 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 1.9984 - accuracy: 0.2968 - val_loss: 2.0148 - val_accuracy: 0.2888 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 1.9977 - accuracy: 0.2983 - val_loss: 2.0161 - val_accuracy: 0.2902 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 1.9950 - accuracy: 0.2969 - val_loss: 2.0101 - val_accuracy: 0.2916 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 1.9936 - accuracy: 0.2991 - val_loss: 2.0094 - val_accuracy: 0.2877 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 1.9933 - accuracy: 0.2972 - val_loss: 2.0054 - val_accuracy: 0.2952 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 22s 57ms/step - loss: 1.9905 - accuracy: 0.2994 - val_loss: 2.0064 - val_accuracy: 0.2909 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 1.9895 - accuracy: 0.2999 - val_loss: 2.0041 - val_accuracy: 0.2907 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 1.9891 - accuracy: 0.3000 - val_loss: 2.0128 - val_accuracy: 0.2935 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 1.9872 - accuracy: 0.3023 - val_loss: 2.0016 - val_accuracy: 0.2916 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 27s 73ms/step - loss: 1.9885 - accuracy: 0.3011 - val_loss: 2.0007 - val_accuracy: 0.2866 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 28s 76ms/step - loss: 1.9864 - accuracy: 0.2996 - val_loss: 2.0030 - val_accuracy: 0.2890 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 1.9854 - accuracy: 0.3000 - val_loss: 2.0001 - val_accuracy: 0.2909 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 1.9868 - accuracy: 0.3015 - val_loss: 2.0049 - val_accuracy: 0.2887 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 1.9843 - accuracy: 0.3009 - val_loss: 1.9999 - val_accuracy: 0.3027 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 1.9834 - accuracy: 0.3033 - val_loss: 1.9987 - val_accuracy: 0.2983 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 1.9837 - accuracy: 0.3030 - val_loss: 1.9992 - val_accuracy: 0.2894 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 1.9818 - accuracy: 0.3042 - val_loss: 1.9961 - val_accuracy: 0.2963 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 1.9822 - accuracy: 0.3032 - val_loss: 1.9972 - val_accuracy: 0.2957 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 1.9800 - accuracy: 0.3030 - val_loss: 1.9980 - val_accuracy: 0.2967 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 1.9792 - accuracy: 0.3048 - val_loss: 1.9921 - val_accuracy: 0.3122 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 1.9776 - accuracy: 0.3049 - val_loss: 1.9907 - val_accuracy: 0.3033 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 1.9763 - accuracy: 0.3056 - val_loss: 1.9914 - val_accuracy: 0.3056 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 1.9763 - accuracy: 0.3068 - val_loss: 1.9883 - val_accuracy: 0.3004 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 1.9722 - accuracy: 0.3081 - val_loss: 1.9911 - val_accuracy: 0.3047 - lr: 0.0100\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 28s 76ms/step - loss: 1.9700 - accuracy: 0.3087 - val_loss: 1.9814 - val_accuracy: 0.3105 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 1.9669 - accuracy: 0.3098 - val_loss: 1.9826 - val_accuracy: 0.3087 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 1.9637 - accuracy: 0.3124 - val_loss: 1.9692 - val_accuracy: 0.3159 - lr: 0.0100\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 26s 68ms/step - loss: 1.9584 - accuracy: 0.3146 - val_loss: 1.9643 - val_accuracy: 0.3115 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 1.9513 - accuracy: 0.3204 - val_loss: 1.9578 - val_accuracy: 0.3246 - lr: 0.0100\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 25s 68ms/step - loss: 1.9468 - accuracy: 0.3214 - val_loss: 1.9539 - val_accuracy: 0.3291 - lr: 0.0100\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 1.9417 - accuracy: 0.3266 - val_loss: 1.9577 - val_accuracy: 0.3223 - lr: 0.0100\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 28s 73ms/step - loss: 1.9398 - accuracy: 0.3299 - val_loss: 1.9444 - val_accuracy: 0.3318 - lr: 0.0100\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 27s 73ms/step - loss: 1.9359 - accuracy: 0.3314 - val_loss: 1.9411 - val_accuracy: 0.3413 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 1.9357 - accuracy: 0.3337 - val_loss: 1.9461 - val_accuracy: 0.3259 - lr: 0.0100\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 30s 80ms/step - loss: 1.9321 - accuracy: 0.3356 - val_loss: 1.9611 - val_accuracy: 0.3226 - lr: 0.0100\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 29s 77ms/step - loss: 1.9302 - accuracy: 0.3386 - val_loss: 1.9430 - val_accuracy: 0.3375 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2545 - accuracy: 0.1391 - val_loss: 2.1979 - val_accuracy: 0.1579 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1825 - accuracy: 0.1784 - val_loss: 2.1661 - val_accuracy: 0.1900 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1615 - accuracy: 0.1851 - val_loss: 2.1532 - val_accuracy: 0.1760 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1526 - accuracy: 0.1876 - val_loss: 2.1457 - val_accuracy: 0.1898 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1474 - accuracy: 0.1910 - val_loss: 2.1419 - val_accuracy: 0.1936 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1438 - accuracy: 0.1934 - val_loss: 2.1387 - val_accuracy: 0.1930 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1407 - accuracy: 0.1958 - val_loss: 2.1382 - val_accuracy: 0.1984 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1388 - accuracy: 0.1965 - val_loss: 2.1335 - val_accuracy: 0.1963 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1364 - accuracy: 0.1975 - val_loss: 2.1316 - val_accuracy: 0.2032 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1345 - accuracy: 0.1986 - val_loss: 2.1294 - val_accuracy: 0.2036 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1327 - accuracy: 0.1993 - val_loss: 2.1277 - val_accuracy: 0.2049 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1309 - accuracy: 0.2023 - val_loss: 2.1265 - val_accuracy: 0.1983 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1293 - accuracy: 0.2029 - val_loss: 2.1258 - val_accuracy: 0.2035 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.1279 - accuracy: 0.2044 - val_loss: 2.1242 - val_accuracy: 0.2097 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.1262 - accuracy: 0.2045 - val_loss: 2.1225 - val_accuracy: 0.2105 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1250 - accuracy: 0.2052 - val_loss: 2.1199 - val_accuracy: 0.2075 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.1236 - accuracy: 0.2062 - val_loss: 2.1180 - val_accuracy: 0.2114 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1218 - accuracy: 0.2076 - val_loss: 2.1176 - val_accuracy: 0.2028 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1209 - accuracy: 0.2053 - val_loss: 2.1157 - val_accuracy: 0.2118 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1198 - accuracy: 0.2068 - val_loss: 2.1153 - val_accuracy: 0.2077 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 2.1189 - accuracy: 0.2082 - val_loss: 2.1133 - val_accuracy: 0.2145 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 2.1176 - accuracy: 0.2101 - val_loss: 2.1127 - val_accuracy: 0.2100 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.1165 - accuracy: 0.2106 - val_loss: 2.1107 - val_accuracy: 0.2145 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1153 - accuracy: 0.2100 - val_loss: 2.1098 - val_accuracy: 0.2175 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1143 - accuracy: 0.2121 - val_loss: 2.1083 - val_accuracy: 0.2179 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1133 - accuracy: 0.2118 - val_loss: 2.1080 - val_accuracy: 0.2151 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1122 - accuracy: 0.2136 - val_loss: 2.1073 - val_accuracy: 0.2222 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 2.1114 - accuracy: 0.2132 - val_loss: 2.1062 - val_accuracy: 0.2263 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1106 - accuracy: 0.2143 - val_loss: 2.1045 - val_accuracy: 0.2150 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.1099 - accuracy: 0.2140 - val_loss: 2.1040 - val_accuracy: 0.2264 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1090 - accuracy: 0.2158 - val_loss: 2.1030 - val_accuracy: 0.2184 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1080 - accuracy: 0.2140 - val_loss: 2.1022 - val_accuracy: 0.2150 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1072 - accuracy: 0.2154 - val_loss: 2.1014 - val_accuracy: 0.2226 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1067 - accuracy: 0.2164 - val_loss: 2.1011 - val_accuracy: 0.2231 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.1058 - accuracy: 0.2183 - val_loss: 2.1001 - val_accuracy: 0.2234 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1052 - accuracy: 0.2170 - val_loss: 2.0993 - val_accuracy: 0.2179 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.1042 - accuracy: 0.2180 - val_loss: 2.0979 - val_accuracy: 0.2206 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1035 - accuracy: 0.2171 - val_loss: 2.0976 - val_accuracy: 0.2281 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.1029 - accuracy: 0.2195 - val_loss: 2.0966 - val_accuracy: 0.2298 - lr: 0.0100\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1024 - accuracy: 0.2181 - val_loss: 2.0966 - val_accuracy: 0.2294 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1019 - accuracy: 0.2192 - val_loss: 2.0952 - val_accuracy: 0.2227 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.1011 - accuracy: 0.2193 - val_loss: 2.0963 - val_accuracy: 0.2351 - lr: 0.0100\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.1008 - accuracy: 0.2191 - val_loss: 2.0942 - val_accuracy: 0.2278 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0999 - accuracy: 0.2191 - val_loss: 2.0944 - val_accuracy: 0.2227 - lr: 0.0100\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0993 - accuracy: 0.2209 - val_loss: 2.0929 - val_accuracy: 0.2323 - lr: 0.0100\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0987 - accuracy: 0.2206 - val_loss: 2.0928 - val_accuracy: 0.2255 - lr: 0.0100\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0982 - accuracy: 0.2231 - val_loss: 2.0922 - val_accuracy: 0.2175 - lr: 0.0100\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0977 - accuracy: 0.2205 - val_loss: 2.0912 - val_accuracy: 0.2275 - lr: 0.0100\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0971 - accuracy: 0.2215 - val_loss: 2.0908 - val_accuracy: 0.2302 - lr: 0.0100\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0966 - accuracy: 0.2221 - val_loss: 2.0901 - val_accuracy: 0.2312 - lr: 0.0100\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0963 - accuracy: 0.2209 - val_loss: 2.0905 - val_accuracy: 0.2256 - lr: 0.0100\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 52/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0958 - accuracy: 0.2247 - val_loss: 2.0891 - val_accuracy: 0.2259 - lr: 0.0100\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 53/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0951 - accuracy: 0.2233 - val_loss: 2.0892 - val_accuracy: 0.2315 - lr: 0.0100\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 54/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 2.0946 - accuracy: 0.2246 - val_loss: 2.0882 - val_accuracy: 0.2268 - lr: 0.0100\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 55/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0944 - accuracy: 0.2237 - val_loss: 2.0879 - val_accuracy: 0.2253 - lr: 0.0100\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 56/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0939 - accuracy: 0.2237 - val_loss: 2.0892 - val_accuracy: 0.2276 - lr: 0.0100\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 57/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0934 - accuracy: 0.2229 - val_loss: 2.0874 - val_accuracy: 0.2296 - lr: 0.0100\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 58/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0932 - accuracy: 0.2230 - val_loss: 2.0864 - val_accuracy: 0.2338 - lr: 0.0100\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 59/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0928 - accuracy: 0.2226 - val_loss: 2.0864 - val_accuracy: 0.2317 - lr: 0.0100\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 60/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0920 - accuracy: 0.2263 - val_loss: 2.0863 - val_accuracy: 0.2298 - lr: 0.0100\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 61/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0919 - accuracy: 0.2256 - val_loss: 2.0860 - val_accuracy: 0.2325 - lr: 0.0100\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 62/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0914 - accuracy: 0.2260 - val_loss: 2.0849 - val_accuracy: 0.2340 - lr: 0.0100\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 63/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0911 - accuracy: 0.2266 - val_loss: 2.0843 - val_accuracy: 0.2317 - lr: 0.0100\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 64/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0905 - accuracy: 0.2267 - val_loss: 2.0841 - val_accuracy: 0.2253 - lr: 0.0100\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 65/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0901 - accuracy: 0.2254 - val_loss: 2.0846 - val_accuracy: 0.2357 - lr: 0.0100\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 66/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0898 - accuracy: 0.2256 - val_loss: 2.0837 - val_accuracy: 0.2369 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 67/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0894 - accuracy: 0.2293 - val_loss: 2.0834 - val_accuracy: 0.2259 - lr: 0.0100\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 68/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0891 - accuracy: 0.2263 - val_loss: 2.0827 - val_accuracy: 0.2313 - lr: 0.0100\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 69/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0886 - accuracy: 0.2262 - val_loss: 2.0821 - val_accuracy: 0.2385 - lr: 0.0100\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 70/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0885 - accuracy: 0.2274 - val_loss: 2.0812 - val_accuracy: 0.2337 - lr: 0.0100\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 71/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0883 - accuracy: 0.2273 - val_loss: 2.0818 - val_accuracy: 0.2370 - lr: 0.0100\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 72/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0877 - accuracy: 0.2278 - val_loss: 2.0810 - val_accuracy: 0.2412 - lr: 0.0100\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 73/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0874 - accuracy: 0.2293 - val_loss: 2.0810 - val_accuracy: 0.2290 - lr: 0.0100\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 74/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0871 - accuracy: 0.2278 - val_loss: 2.0824 - val_accuracy: 0.2357 - lr: 0.0100\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 75/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0869 - accuracy: 0.2282 - val_loss: 2.0809 - val_accuracy: 0.2373 - lr: 0.0100\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 76/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0866 - accuracy: 0.2285 - val_loss: 2.0813 - val_accuracy: 0.2322 - lr: 0.0100\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 77/80\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 2.0863 - accuracy: 0.2290 - val_loss: 2.0793 - val_accuracy: 0.2363 - lr: 0.0100\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 78/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0856 - accuracy: 0.2300 - val_loss: 2.0786 - val_accuracy: 0.2345 - lr: 0.0100\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 79/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0855 - accuracy: 0.2288 - val_loss: 2.0792 - val_accuracy: 0.2365 - lr: 0.0100\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 80/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0853 - accuracy: 0.2298 - val_loss: 2.0779 - val_accuracy: 0.2394 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.5740 - accuracy: 0.0882 - val_loss: 2.5722 - val_accuracy: 0.0862 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.5740 - accuracy: 0.0882 - val_loss: 2.5722 - val_accuracy: 0.0862 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.5740 - accuracy: 0.0882 - val_loss: 2.5722 - val_accuracy: 0.0862 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.5740 - accuracy: 0.0882 - val_loss: 2.5722 - val_accuracy: 0.0862 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.4811 - accuracy: 0.5114 - val_loss: 0.9821 - val_accuracy: 0.6888 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.7288 - accuracy: 0.7916 - val_loss: 0.7023 - val_accuracy: 0.8150 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 0.5388 - accuracy: 0.8549 - val_loss: 0.5118 - val_accuracy: 0.8633 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.4536 - accuracy: 0.8783 - val_loss: 0.4069 - val_accuracy: 0.8898 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.4100 - accuracy: 0.8885 - val_loss: 0.4004 - val_accuracy: 0.8926 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.3810 - accuracy: 0.8951 - val_loss: 0.3593 - val_accuracy: 0.9035 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.3601 - accuracy: 0.9013 - val_loss: 0.3533 - val_accuracy: 0.9028 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 0.3500 - accuracy: 0.9036 - val_loss: 0.3197 - val_accuracy: 0.9106 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 0.3352 - accuracy: 0.9074 - val_loss: 0.3173 - val_accuracy: 0.9120 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 0.3252 - accuracy: 0.9105 - val_loss: 0.3028 - val_accuracy: 0.9172 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.3120 - accuracy: 0.9144 - val_loss: 0.2955 - val_accuracy: 0.9179 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.3038 - accuracy: 0.9170 - val_loss: 0.2879 - val_accuracy: 0.9182 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.2912 - accuracy: 0.9199 - val_loss: 0.2768 - val_accuracy: 0.9245 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.2923 - accuracy: 0.9197 - val_loss: 0.2899 - val_accuracy: 0.9204 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 0.2806 - accuracy: 0.9238 - val_loss: 0.2757 - val_accuracy: 0.9225 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 0.2721 - accuracy: 0.9250 - val_loss: 0.2709 - val_accuracy: 0.9253 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 15s 40ms/step - loss: 0.2685 - accuracy: 0.9249 - val_loss: 0.2808 - val_accuracy: 0.9226 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 0.2627 - accuracy: 0.9261 - val_loss: 0.2714 - val_accuracy: 0.9273 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.2614 - accuracy: 0.9263 - val_loss: 0.2571 - val_accuracy: 0.9268 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.2540 - accuracy: 0.9291 - val_loss: 0.2706 - val_accuracy: 0.9253 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.2551 - accuracy: 0.9281 - val_loss: 0.2643 - val_accuracy: 0.9266 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.2487 - accuracy: 0.9309 - val_loss: 0.2684 - val_accuracy: 0.9225 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.3042 - accuracy: 0.5283 - val_loss: 0.8677 - val_accuracy: 0.6771 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.7906 - accuracy: 0.7437 - val_loss: 0.6952 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6071 - accuracy: 0.8244 - val_loss: 0.5612 - val_accuracy: 0.8405 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.5222 - accuracy: 0.8560 - val_loss: 0.5185 - val_accuracy: 0.8581 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4650 - accuracy: 0.8752 - val_loss: 0.4596 - val_accuracy: 0.8773 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4340 - accuracy: 0.8846 - val_loss: 0.4248 - val_accuracy: 0.8806 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4101 - accuracy: 0.8899 - val_loss: 0.4293 - val_accuracy: 0.8801 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3882 - accuracy: 0.8963 - val_loss: 0.3918 - val_accuracy: 0.8961 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3729 - accuracy: 0.8997 - val_loss: 0.3993 - val_accuracy: 0.8947 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3578 - accuracy: 0.9027 - val_loss: 0.3647 - val_accuracy: 0.9003 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3430 - accuracy: 0.9071 - val_loss: 0.3731 - val_accuracy: 0.8991 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3337 - accuracy: 0.9096 - val_loss: 0.3425 - val_accuracy: 0.9090 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3341 - accuracy: 0.9117 - val_loss: 0.3415 - val_accuracy: 0.9105 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3216 - accuracy: 0.9137 - val_loss: 0.3345 - val_accuracy: 0.9097 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3094 - accuracy: 0.9172 - val_loss: 0.3451 - val_accuracy: 0.9047 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3057 - accuracy: 0.9176 - val_loss: 0.3296 - val_accuracy: 0.9109 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2907 - accuracy: 0.9220 - val_loss: 0.3210 - val_accuracy: 0.9112 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2857 - accuracy: 0.9221 - val_loss: 0.3290 - val_accuracy: 0.9122 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2835 - accuracy: 0.9231 - val_loss: 0.3110 - val_accuracy: 0.9160 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2758 - accuracy: 0.9246 - val_loss: 0.3318 - val_accuracy: 0.9111 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2696 - accuracy: 0.9271 - val_loss: 0.3107 - val_accuracy: 0.9168 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2626 - accuracy: 0.9284 - val_loss: 0.3039 - val_accuracy: 0.9206 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2622 - accuracy: 0.9297 - val_loss: 0.3264 - val_accuracy: 0.9109 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2565 - accuracy: 0.9305 - val_loss: 0.3061 - val_accuracy: 0.9183 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2519 - accuracy: 0.9312 - val_loss: 0.3150 - val_accuracy: 0.9195 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 2.2912 - accuracy: 0.1346 - val_loss: 2.2620 - val_accuracy: 0.1562 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 2.2424 - accuracy: 0.1597 - val_loss: 2.2320 - val_accuracy: 0.1718 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.2176 - accuracy: 0.1927 - val_loss: 2.2029 - val_accuracy: 0.2152 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.2000 - accuracy: 0.2108 - val_loss: 2.1887 - val_accuracy: 0.2174 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 2.1916 - accuracy: 0.2100 - val_loss: 2.1848 - val_accuracy: 0.2104 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 16s 41ms/step - loss: 2.1854 - accuracy: 0.2125 - val_loss: 2.1788 - val_accuracy: 0.2177 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 2.1807 - accuracy: 0.2139 - val_loss: 2.1781 - val_accuracy: 0.2159 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 2.1782 - accuracy: 0.2163 - val_loss: 2.1686 - val_accuracy: 0.2173 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 2.1733 - accuracy: 0.2188 - val_loss: 2.1661 - val_accuracy: 0.2171 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.1702 - accuracy: 0.2210 - val_loss: 2.1599 - val_accuracy: 0.2249 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 17s 47ms/step - loss: 2.1654 - accuracy: 0.2228 - val_loss: 2.1557 - val_accuracy: 0.2206 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 2.1605 - accuracy: 0.2265 - val_loss: 2.1510 - val_accuracy: 0.2335 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1592 - accuracy: 0.2263 - val_loss: 2.1461 - val_accuracy: 0.2324 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1550 - accuracy: 0.2289 - val_loss: 2.1469 - val_accuracy: 0.2352 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1542 - accuracy: 0.2242 - val_loss: 2.1456 - val_accuracy: 0.2256 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 2.1520 - accuracy: 0.2277 - val_loss: 2.1422 - val_accuracy: 0.2308 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 15s 39ms/step - loss: 2.1518 - accuracy: 0.2235 - val_loss: 2.1383 - val_accuracy: 0.2275 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 2.1496 - accuracy: 0.2234 - val_loss: 2.1420 - val_accuracy: 0.2329 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 2.1490 - accuracy: 0.2255 - val_loss: 2.1354 - val_accuracy: 0.2269 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 22s 57ms/step - loss: 2.1463 - accuracy: 0.2242 - val_loss: 2.1356 - val_accuracy: 0.2257 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 2.1458 - accuracy: 0.2254 - val_loss: 2.1384 - val_accuracy: 0.2301 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 2.1455 - accuracy: 0.2255 - val_loss: 2.1343 - val_accuracy: 0.2258 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 2.1436 - accuracy: 0.2246 - val_loss: 2.1337 - val_accuracy: 0.2270 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 15s 39ms/step - loss: 2.1420 - accuracy: 0.2248 - val_loss: 2.1315 - val_accuracy: 0.2273 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 2.1403 - accuracy: 0.2279 - val_loss: 2.1322 - val_accuracy: 0.2282 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.1386 - accuracy: 0.2276 - val_loss: 2.1285 - val_accuracy: 0.2319 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 16s 44ms/step - loss: 2.1360 - accuracy: 0.2268 - val_loss: 2.1276 - val_accuracy: 0.2303 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1374 - accuracy: 0.2276 - val_loss: 2.1302 - val_accuracy: 0.2327 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 2.1349 - accuracy: 0.2301 - val_loss: 2.1293 - val_accuracy: 0.2271 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 2.1322 - accuracy: 0.2303 - val_loss: 2.1262 - val_accuracy: 0.2381 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1309 - accuracy: 0.2357 - val_loss: 2.1242 - val_accuracy: 0.2406 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 2.1279 - accuracy: 0.2396 - val_loss: 2.1236 - val_accuracy: 0.2415 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 2.1240 - accuracy: 0.2461 - val_loss: 2.1153 - val_accuracy: 0.2486 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1222 - accuracy: 0.2496 - val_loss: 2.1193 - val_accuracy: 0.2559 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 2.1193 - accuracy: 0.2508 - val_loss: 2.1142 - val_accuracy: 0.2497 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 2.1187 - accuracy: 0.2490 - val_loss: 2.1119 - val_accuracy: 0.2473 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 2.1184 - accuracy: 0.2484 - val_loss: 2.1087 - val_accuracy: 0.2512 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 2.1150 - accuracy: 0.2501 - val_loss: 2.1078 - val_accuracy: 0.2494 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1140 - accuracy: 0.2506 - val_loss: 2.1060 - val_accuracy: 0.2548 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 2.1145 - accuracy: 0.2496 - val_loss: 2.1026 - val_accuracy: 0.2532 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 2.1110 - accuracy: 0.2490 - val_loss: 2.1005 - val_accuracy: 0.2542 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 2.1105 - accuracy: 0.2495 - val_loss: 2.1067 - val_accuracy: 0.2454 - lr: 0.0100\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 2.1114 - accuracy: 0.2473 - val_loss: 2.1041 - val_accuracy: 0.2474 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 2.1109 - accuracy: 0.2478 - val_loss: 2.1027 - val_accuracy: 0.2567 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 15s 38ms/step - loss: 2.1271 - accuracy: 0.2302 - val_loss: 2.0133 - val_accuracy: 0.2640 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 14s 39ms/step - loss: 1.9543 - accuracy: 0.2890 - val_loss: 1.9195 - val_accuracy: 0.3127 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 1.9167 - accuracy: 0.3122 - val_loss: 1.8848 - val_accuracy: 0.3192 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 15s 39ms/step - loss: 1.8970 - accuracy: 0.3161 - val_loss: 1.8653 - val_accuracy: 0.3245 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.8788 - accuracy: 0.3200 - val_loss: 1.8509 - val_accuracy: 0.3271 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 1.8646 - accuracy: 0.3256 - val_loss: 1.8341 - val_accuracy: 0.3333 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 16s 41ms/step - loss: 1.8477 - accuracy: 0.3328 - val_loss: 1.8195 - val_accuracy: 0.3439 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 1.8335 - accuracy: 0.3471 - val_loss: 1.8056 - val_accuracy: 0.3486 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 16s 41ms/step - loss: 1.8217 - accuracy: 0.3508 - val_loss: 1.7861 - val_accuracy: 0.3616 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 1.8116 - accuracy: 0.3566 - val_loss: 1.7754 - val_accuracy: 0.3643 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 1.8029 - accuracy: 0.3602 - val_loss: 1.7664 - val_accuracy: 0.3734 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 1.7883 - accuracy: 0.3693 - val_loss: 1.7533 - val_accuracy: 0.3802 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.7788 - accuracy: 0.3739 - val_loss: 1.7736 - val_accuracy: 0.3733 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 15s 41ms/step - loss: 1.7700 - accuracy: 0.3824 - val_loss: 1.7506 - val_accuracy: 0.3968 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 1.7590 - accuracy: 0.3861 - val_loss: 1.7358 - val_accuracy: 0.3937 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 1.7522 - accuracy: 0.3897 - val_loss: 1.7290 - val_accuracy: 0.4009 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 1.7431 - accuracy: 0.3910 - val_loss: 1.7084 - val_accuracy: 0.4025 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.7293 - accuracy: 0.3982 - val_loss: 1.7110 - val_accuracy: 0.3998 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.7200 - accuracy: 0.4007 - val_loss: 1.6905 - val_accuracy: 0.4081 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 1.7094 - accuracy: 0.4028 - val_loss: 1.6833 - val_accuracy: 0.4122 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 1.7001 - accuracy: 0.4026 - val_loss: 1.7006 - val_accuracy: 0.4002 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 1.6935 - accuracy: 0.4049 - val_loss: 1.6858 - val_accuracy: 0.4128 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.6881 - accuracy: 0.4082 - val_loss: 1.6553 - val_accuracy: 0.4213 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 1.6789 - accuracy: 0.4125 - val_loss: 1.6514 - val_accuracy: 0.4259 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 1.6714 - accuracy: 0.4165 - val_loss: 1.6739 - val_accuracy: 0.4068 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 1.6621 - accuracy: 0.4180 - val_loss: 1.6441 - val_accuracy: 0.4314 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.6531 - accuracy: 0.4230 - val_loss: 1.6389 - val_accuracy: 0.4297 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.6506 - accuracy: 0.4253 - val_loss: 1.6243 - val_accuracy: 0.4283 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 1.6429 - accuracy: 0.4287 - val_loss: 1.6188 - val_accuracy: 0.4345 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 18s 47ms/step - loss: 1.6382 - accuracy: 0.4293 - val_loss: 1.6140 - val_accuracy: 0.4347 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 1.6391 - accuracy: 0.4279 - val_loss: 1.5989 - val_accuracy: 0.4391 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.6339 - accuracy: 0.4286 - val_loss: 1.6068 - val_accuracy: 0.4392 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 16s 43ms/step - loss: 1.6311 - accuracy: 0.4311 - val_loss: 1.6016 - val_accuracy: 0.4411 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 1.6270 - accuracy: 0.4348 - val_loss: 1.6374 - val_accuracy: 0.4272 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 33s 89ms/step - loss: 2.2437 - accuracy: 0.1816 - val_loss: 2.1927 - val_accuracy: 0.2127 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 32s 84ms/step - loss: 2.1338 - accuracy: 0.2262 - val_loss: 2.1000 - val_accuracy: 0.2196 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 51s 135ms/step - loss: 2.0730 - accuracy: 0.2444 - val_loss: 2.0704 - val_accuracy: 0.2403 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 44s 117ms/step - loss: 2.0480 - accuracy: 0.2615 - val_loss: 2.0497 - val_accuracy: 0.2750 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 48s 129ms/step - loss: 2.0254 - accuracy: 0.2777 - val_loss: 2.0238 - val_accuracy: 0.2855 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 49s 131ms/step - loss: 2.0001 - accuracy: 0.2801 - val_loss: 1.9954 - val_accuracy: 0.2861 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 45s 121ms/step - loss: 1.9783 - accuracy: 0.2816 - val_loss: 1.9739 - val_accuracy: 0.2858 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 55s 148ms/step - loss: 1.9641 - accuracy: 0.2863 - val_loss: 1.9594 - val_accuracy: 0.2831 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 42s 111ms/step - loss: 1.9477 - accuracy: 0.2882 - val_loss: 1.9680 - val_accuracy: 0.2871 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 38s 102ms/step - loss: 1.9370 - accuracy: 0.2932 - val_loss: 1.9373 - val_accuracy: 0.2941 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 46s 123ms/step - loss: 1.9261 - accuracy: 0.2989 - val_loss: 1.9327 - val_accuracy: 0.2935 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 39s 103ms/step - loss: 1.9142 - accuracy: 0.2997 - val_loss: 1.9110 - val_accuracy: 0.3002 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 35s 93ms/step - loss: 1.9052 - accuracy: 0.3046 - val_loss: 1.9045 - val_accuracy: 0.2981 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 42s 113ms/step - loss: 1.8954 - accuracy: 0.3071 - val_loss: 1.9003 - val_accuracy: 0.2987 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 39s 105ms/step - loss: 1.8827 - accuracy: 0.3123 - val_loss: 1.8835 - val_accuracy: 0.3087 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 43s 115ms/step - loss: 1.8752 - accuracy: 0.3146 - val_loss: 1.8741 - val_accuracy: 0.3120 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 43s 114ms/step - loss: 1.8646 - accuracy: 0.3205 - val_loss: 1.8696 - val_accuracy: 0.3205 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 34s 90ms/step - loss: 1.8581 - accuracy: 0.3231 - val_loss: 1.8611 - val_accuracy: 0.3237 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 31s 83ms/step - loss: 1.8532 - accuracy: 0.3256 - val_loss: 1.8527 - val_accuracy: 0.3231 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 1.8482 - accuracy: 0.3272 - val_loss: 1.8532 - val_accuracy: 0.3248 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 35s 92ms/step - loss: 1.8465 - accuracy: 0.3289 - val_loss: 1.8459 - val_accuracy: 0.3264 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 1.8445 - accuracy: 0.3300 - val_loss: 1.8452 - val_accuracy: 0.3325 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 29s 77ms/step - loss: 1.8414 - accuracy: 0.3319 - val_loss: 1.8416 - val_accuracy: 0.3327 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 32s 86ms/step - loss: 1.8372 - accuracy: 0.3326 - val_loss: 1.8416 - val_accuracy: 0.3357 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 39s 103ms/step - loss: 1.8335 - accuracy: 0.3365 - val_loss: 1.8331 - val_accuracy: 0.3318 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 36s 97ms/step - loss: 1.8306 - accuracy: 0.3382 - val_loss: 1.8365 - val_accuracy: 0.3364 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 31s 82ms/step - loss: 1.8268 - accuracy: 0.3407 - val_loss: 1.8362 - val_accuracy: 0.3431 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 29s 77ms/step - loss: 1.8239 - accuracy: 0.3424 - val_loss: 1.8257 - val_accuracy: 0.3388 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 1.8219 - accuracy: 0.3434 - val_loss: 1.8245 - val_accuracy: 0.3441 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 34s 91ms/step - loss: 1.8182 - accuracy: 0.3473 - val_loss: 1.8203 - val_accuracy: 0.3413 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 32s 85ms/step - loss: 1.8147 - accuracy: 0.3487 - val_loss: 1.8557 - val_accuracy: 0.3355 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 32s 85ms/step - loss: 1.8092 - accuracy: 0.3491 - val_loss: 1.8091 - val_accuracy: 0.3495 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 31s 84ms/step - loss: 1.8066 - accuracy: 0.3549 - val_loss: 1.8053 - val_accuracy: 0.3537 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 39s 103ms/step - loss: 1.8025 - accuracy: 0.3581 - val_loss: 1.7999 - val_accuracy: 0.3504 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 33s 88ms/step - loss: 1.8001 - accuracy: 0.3574 - val_loss: 1.8081 - val_accuracy: 0.3445 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 33s 88ms/step - loss: 1.7959 - accuracy: 0.3608 - val_loss: 1.8087 - val_accuracy: 0.3575 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 36s 97ms/step - loss: 1.7938 - accuracy: 0.3601 - val_loss: 1.8153 - val_accuracy: 0.3533 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2353 - accuracy: 0.1864 - val_loss: 2.1541 - val_accuracy: 0.2211 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.1348 - accuracy: 0.2308 - val_loss: 2.1189 - val_accuracy: 0.2456 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.1084 - accuracy: 0.2470 - val_loss: 2.0977 - val_accuracy: 0.2558 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.0921 - accuracy: 0.2525 - val_loss: 2.0845 - val_accuracy: 0.2567 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.0817 - accuracy: 0.2538 - val_loss: 2.0754 - val_accuracy: 0.2542 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.0728 - accuracy: 0.2571 - val_loss: 2.0694 - val_accuracy: 0.2569 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0659 - accuracy: 0.2590 - val_loss: 2.0627 - val_accuracy: 0.2612 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.0610 - accuracy: 0.2608 - val_loss: 2.0606 - val_accuracy: 0.2583 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0561 - accuracy: 0.2614 - val_loss: 2.0516 - val_accuracy: 0.2638 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.0520 - accuracy: 0.2635 - val_loss: 2.0468 - val_accuracy: 0.2690 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 2.0477 - accuracy: 0.2662 - val_loss: 2.0431 - val_accuracy: 0.2680 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.0451 - accuracy: 0.2663 - val_loss: 2.0413 - val_accuracy: 0.2681 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.0412 - accuracy: 0.2680 - val_loss: 2.0362 - val_accuracy: 0.2717 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.0389 - accuracy: 0.2705 - val_loss: 2.0343 - val_accuracy: 0.2723 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0361 - accuracy: 0.2705 - val_loss: 2.0318 - val_accuracy: 0.2718 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 2.0332 - accuracy: 0.2712 - val_loss: 2.0303 - val_accuracy: 0.2752 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0320 - accuracy: 0.2731 - val_loss: 2.0276 - val_accuracy: 0.2795 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 2.0282 - accuracy: 0.2756 - val_loss: 2.0269 - val_accuracy: 0.2703 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0267 - accuracy: 0.2756 - val_loss: 2.0229 - val_accuracy: 0.2825 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.0243 - accuracy: 0.2777 - val_loss: 2.0208 - val_accuracy: 0.2802 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.0231 - accuracy: 0.2785 - val_loss: 2.0181 - val_accuracy: 0.2811 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0208 - accuracy: 0.2787 - val_loss: 2.0159 - val_accuracy: 0.2833 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0191 - accuracy: 0.2814 - val_loss: 2.0135 - val_accuracy: 0.2848 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.0179 - accuracy: 0.2806 - val_loss: 2.0156 - val_accuracy: 0.2784 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0159 - accuracy: 0.2808 - val_loss: 2.0115 - val_accuracy: 0.2854 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.0143 - accuracy: 0.2835 - val_loss: 2.0114 - val_accuracy: 0.2842 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0129 - accuracy: 0.2820 - val_loss: 2.0096 - val_accuracy: 0.2845 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 6s 16ms/step - loss: 2.0118 - accuracy: 0.2828 - val_loss: 2.0087 - val_accuracy: 0.2863 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 2.0103 - accuracy: 0.2852 - val_loss: 2.0064 - val_accuracy: 0.2852 - lr: 0.0100\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0087 - accuracy: 0.2849 - val_loss: 2.0060 - val_accuracy: 0.2799 - lr: 0.0100\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0078 - accuracy: 0.2851 - val_loss: 2.0061 - val_accuracy: 0.2910 - lr: 0.0100\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0069 - accuracy: 0.2852 - val_loss: 2.0007 - val_accuracy: 0.2885 - lr: 0.0100\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 2.0050 - accuracy: 0.2864 - val_loss: 2.0028 - val_accuracy: 0.2891 - lr: 0.0100\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0040 - accuracy: 0.2858 - val_loss: 2.0018 - val_accuracy: 0.2910 - lr: 0.0100\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 2.0029 - accuracy: 0.2871 - val_loss: 1.9985 - val_accuracy: 0.2889 - lr: 0.0100\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0011 - accuracy: 0.2876 - val_loss: 1.9983 - val_accuracy: 0.2872 - lr: 0.0100\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.0005 - accuracy: 0.2886 - val_loss: 1.9989 - val_accuracy: 0.2858 - lr: 0.0100\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.9997 - accuracy: 0.2887 - val_loss: 1.9972 - val_accuracy: 0.2855 - lr: 0.0100\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9983 - accuracy: 0.2880 - val_loss: 1.9943 - val_accuracy: 0.2898 - lr: 0.0100\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.9969 - accuracy: 0.2893 - val_loss: 1.9960 - val_accuracy: 0.2935 - lr: 0.0100\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9959 - accuracy: 0.2912 - val_loss: 1.9907 - val_accuracy: 0.2964 - lr: 0.0100\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.9951 - accuracy: 0.2921 - val_loss: 1.9917 - val_accuracy: 0.2929 - lr: 0.0100\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9944 - accuracy: 0.2910 - val_loss: 1.9901 - val_accuracy: 0.2932 - lr: 0.0100\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9934 - accuracy: 0.2916 - val_loss: 1.9935 - val_accuracy: 0.2921 - lr: 0.0100\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9919 - accuracy: 0.2904 - val_loss: 1.9897 - val_accuracy: 0.2908 - lr: 0.0100\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.9912 - accuracy: 0.2912 - val_loss: 1.9877 - val_accuracy: 0.2950 - lr: 0.0100\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.9905 - accuracy: 0.2918 - val_loss: 1.9873 - val_accuracy: 0.2940 - lr: 0.0100\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.9899 - accuracy: 0.2918 - val_loss: 1.9851 - val_accuracy: 0.2987 - lr: 0.0100\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9888 - accuracy: 0.2932 - val_loss: 1.9836 - val_accuracy: 0.2947 - lr: 0.0100\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.9885 - accuracy: 0.2930 - val_loss: 1.9838 - val_accuracy: 0.2931 - lr: 0.0100\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 51/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9874 - accuracy: 0.2924 - val_loss: 1.9819 - val_accuracy: 0.2953 - lr: 0.0100\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 52/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.9864 - accuracy: 0.2924 - val_loss: 1.9829 - val_accuracy: 0.2982 - lr: 0.0100\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 53/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.9854 - accuracy: 0.2941 - val_loss: 1.9807 - val_accuracy: 0.2988 - lr: 0.0100\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 54/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9851 - accuracy: 0.2938 - val_loss: 1.9841 - val_accuracy: 0.2935 - lr: 0.0100\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 55/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.9847 - accuracy: 0.2941 - val_loss: 1.9789 - val_accuracy: 0.2987 - lr: 0.0100\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 56/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9834 - accuracy: 0.2945 - val_loss: 1.9780 - val_accuracy: 0.2943 - lr: 0.0100\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 57/80\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 1.9832 - accuracy: 0.2941 - val_loss: 1.9803 - val_accuracy: 0.2965 - lr: 0.0100\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 58/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.9819 - accuracy: 0.2947 - val_loss: 1.9794 - val_accuracy: 0.2998 - lr: 0.0100\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 59/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.9808 - accuracy: 0.2961 - val_loss: 1.9784 - val_accuracy: 0.2969 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.5352 - accuracy: 0.0993 - val_loss: 2.5455 - val_accuracy: 0.0957 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 2.5352 - accuracy: 0.0993 - val_loss: 2.5455 - val_accuracy: 0.0957 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.5352 - accuracy: 0.0993 - val_loss: 2.5455 - val_accuracy: 0.0957 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 2.5352 - accuracy: 0.0993 - val_loss: 2.5455 - val_accuracy: 0.0957 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 1.6922 - accuracy: 0.3911 - val_loss: 1.2086 - val_accuracy: 0.5780 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.9910 - accuracy: 0.6534 - val_loss: 1.0371 - val_accuracy: 0.5996 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 26s 70ms/step - loss: 0.7350 - accuracy: 0.7639 - val_loss: 0.6107 - val_accuracy: 0.8100 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.5941 - accuracy: 0.8236 - val_loss: 0.5161 - val_accuracy: 0.8524 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.5157 - accuracy: 0.8522 - val_loss: 0.5139 - val_accuracy: 0.8648 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.4655 - accuracy: 0.8705 - val_loss: 0.4182 - val_accuracy: 0.8851 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 0.4153 - accuracy: 0.8844 - val_loss: 0.3864 - val_accuracy: 0.8911 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.3802 - accuracy: 0.8945 - val_loss: 0.3495 - val_accuracy: 0.9038 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.3543 - accuracy: 0.9018 - val_loss: 0.3543 - val_accuracy: 0.9022 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.3392 - accuracy: 0.9063 - val_loss: 0.3239 - val_accuracy: 0.9098 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3265 - accuracy: 0.9094 - val_loss: 0.3189 - val_accuracy: 0.9125 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 0.3102 - accuracy: 0.9144 - val_loss: 0.2904 - val_accuracy: 0.9178 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 0.3008 - accuracy: 0.9147 - val_loss: 0.3120 - val_accuracy: 0.9097 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.2936 - accuracy: 0.9175 - val_loss: 0.2854 - val_accuracy: 0.9183 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 25s 65ms/step - loss: 0.2830 - accuracy: 0.9205 - val_loss: 0.2600 - val_accuracy: 0.9247 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.2742 - accuracy: 0.9219 - val_loss: 0.2849 - val_accuracy: 0.9186 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 0.2696 - accuracy: 0.9234 - val_loss: 0.2561 - val_accuracy: 0.9283 - lr: 0.0100\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - 29s 78ms/step - loss: 0.2622 - accuracy: 0.9249 - val_loss: 0.2592 - val_accuracy: 0.9252 - lr: 0.0100\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.2549 - accuracy: 0.9261 - val_loss: 0.2577 - val_accuracy: 0.9260 - lr: 0.0100\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - 26s 70ms/step - loss: 0.2492 - accuracy: 0.9271 - val_loss: 0.2506 - val_accuracy: 0.9260 - lr: 0.0100\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.2436 - accuracy: 0.9289 - val_loss: 0.2535 - val_accuracy: 0.9264 - lr: 0.0100\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.2380 - accuracy: 0.9302 - val_loss: 0.2450 - val_accuracy: 0.9288 - lr: 0.0100\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.2364 - accuracy: 0.9321 - val_loss: 0.2447 - val_accuracy: 0.9301 - lr: 0.0100\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.2336 - accuracy: 0.9329 - val_loss: 0.2507 - val_accuracy: 0.9299 - lr: 0.0100\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.2305 - accuracy: 0.9322 - val_loss: 0.2357 - val_accuracy: 0.9314 - lr: 0.0100\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.2290 - accuracy: 0.9326 - val_loss: 0.2299 - val_accuracy: 0.9336 - lr: 0.0100\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.2236 - accuracy: 0.9340 - val_loss: 0.2355 - val_accuracy: 0.9332 - lr: 0.0100\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 0.2239 - accuracy: 0.9336 - val_loss: 0.2410 - val_accuracy: 0.9273 - lr: 0.0100\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.2187 - accuracy: 0.9348 - val_loss: 0.2472 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.6383 - accuracy: 0.3781 - val_loss: 1.1694 - val_accuracy: 0.5908 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.8508 - accuracy: 0.7288 - val_loss: 0.8366 - val_accuracy: 0.7315 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.6251 - accuracy: 0.8151 - val_loss: 0.5310 - val_accuracy: 0.8395 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.5228 - accuracy: 0.8511 - val_loss: 0.4784 - val_accuracy: 0.8692 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4752 - accuracy: 0.8701 - val_loss: 0.4686 - val_accuracy: 0.8745 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4354 - accuracy: 0.8824 - val_loss: 0.4479 - val_accuracy: 0.8797 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4051 - accuracy: 0.8922 - val_loss: 0.3903 - val_accuracy: 0.8977 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3821 - accuracy: 0.8968 - val_loss: 0.4076 - val_accuracy: 0.8892 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.3722 - accuracy: 0.9005 - val_loss: 0.3730 - val_accuracy: 0.8987 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3521 - accuracy: 0.9050 - val_loss: 0.3807 - val_accuracy: 0.8976 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3361 - accuracy: 0.9090 - val_loss: 0.3782 - val_accuracy: 0.8972 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.3238 - accuracy: 0.9130 - val_loss: 0.3314 - val_accuracy: 0.9136 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3176 - accuracy: 0.9143 - val_loss: 0.3408 - val_accuracy: 0.9097 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3082 - accuracy: 0.9177 - val_loss: 0.3251 - val_accuracy: 0.9164 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2989 - accuracy: 0.9190 - val_loss: 0.3284 - val_accuracy: 0.9153 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2991 - accuracy: 0.9202 - val_loss: 0.3424 - val_accuracy: 0.9124 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2861 - accuracy: 0.9235 - val_loss: 0.3258 - val_accuracy: 0.9123 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 2.2218 - accuracy: 0.1711 - val_loss: 2.1370 - val_accuracy: 0.1937 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 2.1093 - accuracy: 0.2229 - val_loss: 2.0706 - val_accuracy: 0.2315 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 2.0715 - accuracy: 0.2370 - val_loss: 2.0367 - val_accuracy: 0.2569 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 2.0489 - accuracy: 0.2485 - val_loss: 2.0400 - val_accuracy: 0.2507 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 2.0341 - accuracy: 0.2745 - val_loss: 2.0540 - val_accuracy: 0.2791 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 2.0202 - accuracy: 0.3015 - val_loss: 2.0033 - val_accuracy: 0.3133 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 2.0069 - accuracy: 0.3098 - val_loss: 1.9945 - val_accuracy: 0.3145 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 1.9935 - accuracy: 0.3144 - val_loss: 1.9911 - val_accuracy: 0.3183 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 1.9847 - accuracy: 0.3178 - val_loss: 1.9594 - val_accuracy: 0.3233 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 1.9750 - accuracy: 0.3197 - val_loss: 1.9755 - val_accuracy: 0.3257 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 1.9711 - accuracy: 0.3201 - val_loss: 1.9643 - val_accuracy: 0.3271 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 1.9670 - accuracy: 0.3229 - val_loss: 1.9591 - val_accuracy: 0.3257 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 1.9645 - accuracy: 0.3240 - val_loss: 1.9512 - val_accuracy: 0.3262 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 1.9599 - accuracy: 0.3280 - val_loss: 1.9397 - val_accuracy: 0.3356 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 1.9607 - accuracy: 0.3261 - val_loss: 1.9450 - val_accuracy: 0.3313 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 1.9644 - accuracy: 0.3248 - val_loss: 1.9671 - val_accuracy: 0.3232 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 1.9788 - accuracy: 0.3216 - val_loss: 1.9748 - val_accuracy: 0.3284 - lr: 0.0100\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 2.2411 - accuracy: 0.1658 - val_loss: 2.1576 - val_accuracy: 0.2188 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 2.0881 - accuracy: 0.2320 - val_loss: 2.0276 - val_accuracy: 0.2640 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 2.0141 - accuracy: 0.2676 - val_loss: 1.9771 - val_accuracy: 0.2738 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 1.9769 - accuracy: 0.2806 - val_loss: 1.9623 - val_accuracy: 0.2820 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 1.9457 - accuracy: 0.2920 - val_loss: 1.9225 - val_accuracy: 0.3019 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 1.9119 - accuracy: 0.2993 - val_loss: 1.9038 - val_accuracy: 0.2988 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 1.8876 - accuracy: 0.3063 - val_loss: 1.8577 - val_accuracy: 0.3157 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 1.8694 - accuracy: 0.3139 - val_loss: 1.8449 - val_accuracy: 0.3164 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - 24s 64ms/step - loss: 1.8593 - accuracy: 0.3202 - val_loss: 1.8517 - val_accuracy: 0.3192 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 1.8485 - accuracy: 0.3249 - val_loss: 1.8372 - val_accuracy: 0.3282 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 1.8411 - accuracy: 0.3292 - val_loss: 1.8187 - val_accuracy: 0.3357 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 1.8330 - accuracy: 0.3309 - val_loss: 1.8168 - val_accuracy: 0.3367 - lr: 0.0100\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 1.8247 - accuracy: 0.3356 - val_loss: 1.8096 - val_accuracy: 0.3411 - lr: 0.0100\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 1.8212 - accuracy: 0.3400 - val_loss: 1.8143 - val_accuracy: 0.3379 - lr: 0.0100\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 1.8137 - accuracy: 0.3438 - val_loss: 1.8031 - val_accuracy: 0.3425 - lr: 0.0100\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 1.8073 - accuracy: 0.3477 - val_loss: 1.7944 - val_accuracy: 0.3495 - lr: 0.0100\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 17/80\n",
      "128/375 [=========>....................] - ETA: 11s - loss: 1.7967 - accuracy: 0.3532"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Compile and fit models\u001b[39;00m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     31\u001b[0m     loss\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy,\n\u001b[1;32m     32\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m),\n\u001b[1;32m     33\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     34\u001b[0m     run_eagerly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m model_histories[depth][key] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1051\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[1;32m   1050\u001b[0m   \u001b[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1038\u001b[0m       run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1039\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1040\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1308\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1311\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1312\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2888\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 3689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:893\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:537\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    507\u001b[0m   \u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m  This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m \n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 537\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:590\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    588\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 590\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes([\n\u001b[1;32m    593\u001b[0m     v \u001b[38;5;28;01mfor\u001b[39;00m g, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m tf\u001b[38;5;241m.\u001b[39mresource\n\u001b[1;32m    595\u001b[0m ])\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:471\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    470\u001b[0m   \u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m   grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1094\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1095\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1096\u001b[0m           output_gradients))\n\u001b[1;32m   1097\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1098\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1100\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1109\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:151\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m num_inputs\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This does not work with v1 TensorArrays.\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly_outside_functions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m control_flow_util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n\u001b[1;32m    153\u001b[0m   gradient_name_scope \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_tape/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m forward_pass_name_scope:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6004\u001b[0m, in \u001b[0;36mexecuting_eagerly_outside_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5979\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecuting_eagerly_outside_functions\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecuting_eagerly_outside_functions\u001b[39m():\n\u001b[1;32m   5981\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns True if executing eagerly, even if inside a graph function.\u001b[39;00m\n\u001b[1;32m   5982\u001b[0m \n\u001b[1;32m   5983\u001b[0m \u001b[38;5;124;03m  This function will check the outermost context for the program and see if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6002\u001b[0m \u001b[38;5;124;03m    boolean, whether the outermost context is in eager mode.\u001b[39;00m\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6004\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   6005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   6006\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py:2219\u001b[0m, in \u001b[0;36mexecuting_eagerly\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_execution_mode \u001b[38;5;241m==\u001b[39m EAGER_MODE\n\u001b[0;32m-> 2219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py:975\u001b[0m, in \u001b[0;36mContext.executing_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecuting_eagerly\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread_local_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_eager\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Init training params\n",
    "epochs = 80\n",
    "batch_size = 128\n",
    "model_histories = {}\n",
    "\n",
    "# Create new time-based log dir\n",
    "log_dir = os.path.join(\n",
    "    \"logs/dense\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "\n",
    "# Train all models in dict\n",
    "for depth, nested in fc_models.items():\n",
    "    model_histories[depth] = {}\n",
    "    log_dir_depth = log_dir + \"/\" + str(depth)\n",
    "\n",
    "    for key, model in nested.items():\n",
    "        # Reinitialize callbacks with new directory\n",
    "        log_dir_depth_key = log_dir_depth + \"/\" + key\n",
    "\n",
    "        callbacks[0] = keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir_depth_key,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            write_images=True,\n",
    "        )\n",
    "        callbacks[1] = CSVLogger(log_dir + \"fit_csv_logger.csv\")\n",
    "\n",
    "        # Compile and fit models\n",
    "        model.compile(\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
    "            metrics=[\"accuracy\"],\n",
    "            run_eagerly=True,\n",
    "        )\n",
    "        model_histories[depth][key] = model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_valid, y_valid),\n",
    "            callbacks=callbacks,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tL3nbOkDzuyG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d02b3702319815d6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d02b3702319815d6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir './logs/dense'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "loss_test_dict = {}\n",
    "acc_test_dict = {}\n",
    "\n",
    "for depth, nested in fc_models.items():\n",
    "    acc_test_dict[depth] = {}\n",
    "    loss_test_dict[depth] = {}\n",
    "    for key, model in nested.items():\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        loss_test_dict[depth][key] = score[0]\n",
    "        acc_test_dict[depth][key] = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dict with acc metrics into dataframe and export\n",
    "acc_test_frame = pd.DataFrame.from_dict(acc_test_dict, orient=\"index\")\n",
    "loss_test_frame = pd.DataFrame.from_dict(loss_test_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save statistics\n",
    "acc_test_frame.to_csv(\n",
    "    \"logs/dense_test_stats_10_14_100_4\"\n",
    "    + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    + \".csv\",\n",
    "    index=True,\n",
    "    index_label=\"layers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjitvcC6zu3n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cov3CH0-QMYX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8d8d09eac6f33054\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8d8d09eac6f33054\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZPKfahnhpS5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for history in fc_model_histories:\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.savefig(\"fc_model_accuracy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMp0AXBPz0KA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeHFdXCMzzRT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save all models\n",
    "for depth, nested in fc_models.items():\n",
    "    for key, model in nested.items():\n",
    "        model.save(\"models/saved764/\" + str(depth) + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3RZOmeyzUZh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXYObER0zzUt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV519U17yRr8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for depth, nested in fc_models.items():\n",
    "    for key, model in nested.items():\n",
    "        # model_histories[key]\n",
    "        hist_df = pd.DataFrame(model_histories[key].history)\n",
    "        # or save to csv:\n",
    "        hist_csv_file = \"history.csv\"\n",
    "        with open(hist_csv_file, mode=\"w\") as f:\n",
    "            hist_df.to_csv(f)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qT3QvFaBZKzQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyFcHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = fc_model_builder(\n",
    "            dense=hp.Boolean(\"dense\"),\n",
    "            bn=hp.Boolean(\"bn\"),\n",
    "            random=not hp.Boolean(\"bn\"),\n",
    "            dense_out=hp.Boolean(\"output\"),\n",
    "        )\n",
    "        model.compile(\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rate=0.1, momentum=0.9),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=128,  # hp.Choice(\"batch_size\", [16, 32, 64, 128])\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LjCNGGfZ3Kg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fc_tuner = kt.RandomSearch(\n",
    "    MyFcHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,\n",
    "    overwrite=True,\n",
    "    # Set a directory to store the intermediate results.\n",
    "    directory=\"/tmp/tb\",\n",
    "    project_name=\"fc_batchnorm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSD4AJgAZ5Gs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fc_tuner.search(x_train, y_train, epochs=2, validation_data=(x_test, y_test), callbacks=[callbacks],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yKTDOlXiIYo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./logs/fc"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
